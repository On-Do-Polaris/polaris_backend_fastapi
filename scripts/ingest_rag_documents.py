#!/usr/bin/env python3
"""
íŒŒì¼ëª…: ingest_rag_documents.py
ìµœì¢… ìˆ˜ì •ì¼: 2025-12-12
ë²„ì „: v01
íŒŒì¼ ê°œìš”: RAG ë¬¸ì„œ íŒŒì‹± ë° Qdrant ì—…ë¡œë“œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì£¼ì˜ì‚¬í•­:
- LlamaParse Free Tier: 1,000 pages/month
- ì‹¤í–‰ ì „ LLAMA_CLOUD_API_KEY í™˜ê²½ë³€ìˆ˜ í™•ì¸
- Qdrant ì„œë²„ ì‹¤í–‰ í™•ì¸ (http://localhost:6333)
- ì²˜ìŒ ì‹¤í–‰ ì‹œì—ë§Œ íŒŒì‹± ìˆ˜í–‰ (ì´í›„ ìºì‹œ ì‚¬ìš©)

ì‚¬ìš©ë²•:
    # ì „ì²´ ë¬¸ì„œ ìˆ˜ì§‘
    python scripts/ingest_rag_documents.py --all

    # íŠ¹ì • ë¬¸ì„œë§Œ ìˆ˜ì§‘
    python scripts/ingest_rag_documents.py --document tcfd

    # ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬íŒŒì‹± (ì£¼ì˜!)
    python scripts/ingest_rag_documents.py --all --force-reparse

    # í†µê³„ë§Œ í™•ì¸
    python scripts/ingest_rag_documents.py --stats
"""

import os
import sys
import argparse
import json
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from ai_agent.services.rag_ingestion_service import RAGIngestionService

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ============================================================
# ë¬¸ì„œ ì„¤ì •
# ============================================================
DOCUMENT_CONFIGS = [
    {
        'file_path': 'ê°ì¢… ìë£Œ/For_RAG/FINAL-2017-TCFD-Report.pdf',
        'metadata': {
            'document_id': 'tcfd_official_2017',
            'document_type': 'guideline',
            'source': 'TCFD',
            'year': 2017,
            'title': 'Final Report: Recommendations of the TCFD',
            'tags': ['tcfd', 'governance', 'strategy', 'risk_management', 'metrics', 'guidelines']
        }
    },
    {
        'file_path': 'ê°ì¢… ìë£Œ/For_RAG/SnP_Climanomics_PangyoDC_Summary_Report_SK C&C_2024-02-08.pdf',
        'metadata': {
            'document_id': 'snp_climanomics_pangyo_2024',
            'document_type': 'analysis',
            'source': 'S&P Global',
            'year': 2024,
            'title': 'Climanomics Pangyo DC Summary Report - SK C&C',
            'tags': ['s&p', 'climanomics', 'physical_risk', 'data_center', 'pangyo', 'analysis']
        }
    }
]


def validate_environment():
    """
    í™˜ê²½ë³€ìˆ˜ ë° í•„ìˆ˜ íŒŒì¼ ê²€ì¦

    Returns:
        bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
    """
    print("\nğŸ” Validating environment...")

    # 1. LLAMA_CLOUD_API_KEY í™•ì¸
    api_key = os.getenv('LLAMA_CLOUD_API_KEY')
    if not api_key:
        print("âŒ LLAMA_CLOUD_API_KEY not found in environment variables")
        print("   Please add it to .env file")
        return False
    print(f"âœ… LLAMA_CLOUD_API_KEY: {api_key[:10]}...")

    # 2. PDF íŒŒì¼ ì¡´ì¬ í™•ì¸
    missing_files = []
    for config in DOCUMENT_CONFIGS:
        file_path = project_root / config['file_path']
        if not file_path.exists():
            missing_files.append(config['file_path'])
        else:
            print(f"âœ… Found: {config['file_path']}")

    if missing_files:
        print(f"\nâŒ Missing files:")
        for file in missing_files:
            print(f"   - {file}")
        return False

    # 3. Qdrant ì—°ê²° í™•ì¸ (ì„ íƒì‚¬í•­)
    qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
    print(f"\nâš ï¸  Qdrant URL: {qdrant_url}")
    print("   (If Qdrant is not running, ingestion will validate structure only)")

    return True


def show_stats():
    """
    íŒŒì‹± ë° RAG í†µê³„ ì¶œë ¥
    """
    print("\nğŸ“Š RAG Ingestion Statistics\n" + "=" * 60)

    try:
        service = RAGIngestionService()
        stats = service.get_ingestion_stats()

        print(json.dumps(stats, indent=2, ensure_ascii=False))

        # LlamaParse ì‚¬ìš©ëŸ‰ ê³„ì‚°
        parser_stats = stats.get('parser_stats', {})
        total_pages = parser_stats.get('total_pages_used', 0)
        remaining = parser_stats.get('remaining_pages', 1000)

        print(f"\nğŸ“„ LlamaParse Usage:")
        print(f"   Total pages used: {total_pages} / 1,000")
        print(f"   Remaining: {remaining} pages")

        # Qdrant ìƒíƒœ
        if stats.get('qdrant_available'):
            print(f"\nğŸ“¦ Qdrant Collections:")

            if 'tcfd_documents' in stats:
                doc_info = stats['tcfd_documents']
                print(f"   tcfd_documents: {doc_info.get('points_count', 0)} documents")

            if 'tcfd_tables' in stats:
                table_info = stats['tcfd_tables']
                print(f"   tcfd_tables: {table_info.get('points_count', 0)} tables")
        else:
            print(f"\nâš ï¸  Qdrant: Not available")

    except Exception as e:
        print(f"âŒ Failed to get statistics: {e}")


def ingest_documents(
    document_filter: str = 'all',
    force_reparse: bool = False
):
    """
    ë¬¸ì„œ íŒŒì‹± ë° Qdrant ì—…ë¡œë“œ

    Args:
        document_filter: 'all', 'tcfd', 'snp'
        force_reparse: ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬íŒŒì‹± ì—¬ë¶€
    """
    # í•„í„°ë§
    configs_to_process = DOCUMENT_CONFIGS

    if document_filter == 'tcfd':
        configs_to_process = [c for c in DOCUMENT_CONFIGS if 'tcfd' in c['metadata']['document_id']]
    elif document_filter == 'snp':
        configs_to_process = [c for c in DOCUMENT_CONFIGS if 'snp' in c['metadata']['document_id']]

    print(f"\nğŸš€ Starting ingestion for {len(configs_to_process)} documents...")
    print(f"   Force reparse: {force_reparse}")
    print("=" * 60)

    # RAG Ingestion Service ì´ˆê¸°í™”
    service = RAGIngestionService()

    # ë¬¸ì„œ ì²˜ë¦¬
    results = []

    for i, config in enumerate(configs_to_process, 1):
        print(f"\n[{i}/{len(configs_to_process)}] Processing: {config['metadata']['title']}")
        print(f"   File: {config['file_path']}")

        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        file_path = project_root / config['file_path']

        try:
            result = service.ingest_pdf(
                file_path=str(file_path),
                document_metadata=config['metadata'],
                force_reparse=force_reparse
            )

            results.append(result)

            # ê²°ê³¼ ì¶œë ¥
            print(f"   âœ… Success:")
            print(f"      - Parsed chunks: {result.get('parsed_chunks', 0)}")
            print(f"      - Text chunks: {result.get('text_chunks_created', 0)}")
            print(f"      - Tables: {result.get('tables_extracted', 0)}")

            if result.get('uploaded_to_qdrant'):
                print(f"      - Uploaded to Qdrant: {result.get('documents_uploaded', 0)} docs, {result.get('tables_uploaded', 0)} tables")
            else:
                print(f"      - Qdrant upload: Skipped (offline mode)")

        except Exception as e:
            print(f"   âŒ Failed: {e}")
            results.append({
                'file_path': config['file_path'],
                'error': str(e),
                'status': 'failed'
            })

    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ Ingestion Summary:")

    success_count = sum(1 for r in results if r.get('uploaded_to_qdrant') or 'error' not in r)
    fail_count = len(results) - success_count

    print(f"   Total: {len(results)} documents")
    print(f"   Success: {success_count}")
    print(f"   Failed: {fail_count}")

    # í†µê³„ ì¶œë ¥
    show_stats()


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    parser = argparse.ArgumentParser(
        description='RAG Document Ingestion Script',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )

    parser.add_argument(
        '--all',
        action='store_true',
        help='Ingest all documents'
    )

    parser.add_argument(
        '--document',
        choices=['tcfd', 'snp'],
        help='Ingest specific document type only'
    )

    parser.add_argument(
        '--force-reparse',
        action='store_true',
        help='Force reparse (ignore cache) - WARNING: consumes LlamaParse quota'
    )

    parser.add_argument(
        '--stats',
        action='store_true',
        help='Show statistics only'
    )

    args = parser.parse_args()

    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    if not validate_environment():
        print("\nâŒ Environment validation failed. Please fix the issues above.")
        sys.exit(1)

    # í†µê³„ë§Œ ì¶œë ¥
    if args.stats:
        show_stats()
        return

    # ë¬¸ì„œ ìˆ˜ì§‘
    if args.all:
        ingest_documents(document_filter='all', force_reparse=args.force_reparse)
    elif args.document:
        ingest_documents(document_filter=args.document, force_reparse=args.force_reparse)
    else:
        parser.print_help()
        print("\nğŸ’¡ Tip: Use --all to ingest all documents, or --document tcfd/snp for specific ones")
        print("        Use --stats to see current statistics without ingesting")


if __name__ == "__main__":
    main()
