"""
Node 2-A Template Loading v2 ê°„ë‹¨ í…ŒìŠ¤íŠ¸

ì‹¤í–‰ ë°©ë²•:
    cd c:/Users/SKAX/Documents/POLARIS/polaris_backend_fastapi-develop
    python -m ai_agent.agents.tcfd_report.test_node2a_simple

í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì‹¤ì œ LLM ì‚¬ìš© ì‹œ):
    set OPENAI_API_KEY=your_key_here
    set USE_REAL_LLM=true
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime


def create_sample_sites_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì‚¬ì—…ì¥ ë°ì´í„° ìƒì„±"""
    return [
        {
            "site_id": "site_001",
            "site_name": "ì„œìš¸ ë³¸ì‚¬",
            "risk_results": [
                {
                    "risk_type": "river_flood",
                    "final_aal": 7.2,
                    "scenarios": {
                        "ssp1_2.6": {"2024": 7.2, "2030": 7.0, "2040": 6.5, "2050": 6.0, "2100": 5.5},
                        "ssp2_4.5": {"2024": 7.2, "2030": 7.5, "2040": 8.2, "2050": 9.0, "2100": 10.1},
                        "ssp3_7.0": {"2024": 7.2, "2030": 8.0, "2040": 9.5, "2050": 11.0, "2100": 12.5},
                        "ssp5_8.5": {"2024": 7.2, "2030": 8.5, "2040": 10.5, "2050": 13.0, "2100": 15.2}
                    }
                },
                {
                    "risk_type": "typhoon",
                    "final_aal": 2.1,
                    "scenarios": {
                        "ssp1_2.6": {"2024": 2.1, "2030": 2.0, "2040": 1.9, "2050": 1.8, "2100": 1.7},
                        "ssp2_4.5": {"2024": 2.1, "2030": 2.2, "2040": 2.5, "2050": 2.8, "2100": 3.1},
                        "ssp3_7.0": {"2024": 2.1, "2030": 2.5, "2040": 3.0, "2050": 3.5, "2100": 4.0},
                        "ssp5_8.5": {"2024": 2.1, "2030": 2.8, "2040": 3.5, "2050": 4.2, "2100": 5.0}
                    }
                }
            ]
        },
        {
            "site_id": "site_002",
            "site_name": "íŒêµ ë°ì´í„°ì„¼í„°",
            "risk_results": [
                {
                    "risk_type": "river_flood",
                    "final_aal": 11.0,
                    "scenarios": {
                        "ssp1_2.6": {"2024": 11.0, "2030": 10.5, "2040": 10.0, "2050": 9.5, "2100": 9.0},
                        "ssp2_4.5": {"2024": 11.0, "2030": 11.5, "2040": 12.5, "2050": 13.5, "2100": 14.8},
                        "ssp3_7.0": {"2024": 11.0, "2030": 12.0, "2040": 14.0, "2050": 16.0, "2100": 18.0},
                        "ssp5_8.5": {"2024": 11.0, "2030": 13.0, "2040": 16.0, "2050": 19.0, "2100": 22.5}
                    }
                },
                {
                    "risk_type": "extreme_heat",
                    "final_aal": 5.5,
                    "scenarios": {
                        "ssp1_2.6": {"2024": 5.5, "2030": 5.3, "2040": 5.0, "2050": 4.8, "2100": 4.5},
                        "ssp2_4.5": {"2024": 5.5, "2030": 6.0, "2040": 7.0, "2050": 8.0, "2100": 9.2},
                        "ssp3_7.0": {"2024": 5.5, "2030": 6.5, "2040": 8.0, "2050": 10.0, "2100": 12.0},
                        "ssp5_8.5": {"2024": 5.5, "2030": 7.0, "2040": 9.5, "2050": 12.0, "2100": 15.0}
                    }
                }
            ]
        }
    ]


def create_sample_report_template():
    """í…ŒìŠ¤íŠ¸ìš© Node 1 í…œí”Œë¦¿ ìƒì„±"""
    return {
        "tone": {
            "formality": "formal",
            "audience": "institutional investors and stakeholders",
            "voice": "data-driven, professional, transparent"
        },
        "scenario_templates": {
            "SSP1-2.6": {"name": "ì§€ì†ê°€ëŠ¥ ë°œì „", "temp_rise": "1.5Â°C", "style": "ë‚™ê´€ì "},
            "SSP2-4.5": {"name": "ì¤‘ê°„ ê²½ë¡œ", "temp_rise": "2.0-2.5Â°C", "style": "ì¤‘ë¦½ì "},
            "SSP5-8.5": {"name": "í™”ì„ì—°ë£Œ ì§‘ì•½", "temp_rise": "4.0Â°C+", "style": "ê²½ê³ ì "}
        },
        "formatting_rules": {
            "headings": "ìˆ«ì. ì œëª© (ì˜ˆ: 1. Governance)",
            "subheadings": "1.1, 1.2 í˜•ì‹",
            "emphasis": "**êµµì€ ê¸€ì”¨** ë˜ëŠ” ë°‘ì¤„"
        },
        "reusable_paragraphs": [
            "ìš°ë¦¬ëŠ” TCFD ê¶Œê³ ì•ˆì— ë”°ë¼ ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.",
            "ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ í†µí•´ ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ì˜ ì¬ë¬´ì  ì˜í–¥ì„ ì •ëŸ‰í™”í–ˆìŠµë‹ˆë‹¤.",
            "í¬íŠ¸í´ë¦¬ì˜¤ AALì€ [ìˆ˜ì¹˜]%ë¡œ ì‚°ì •ë˜ì—ˆìœ¼ë©°, ì´ëŠ” [í•´ì„]ì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
        ]
    }


class MockLLM:
    """Mock LLM (í…ŒìŠ¤íŠ¸ìš©)"""
    async def ainvoke(self, prompt):
        print(f"\n{'='*60}")
        print("ğŸ¤– Mock LLM í˜¸ì¶œ")
        print(f"{'='*60}")
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt):,} ê¸€ì")

        # í‚¤ì›Œë“œ í™•ì¸
        if "scenario" in prompt.lower() or "ì‹œë‚˜ë¦¬ì˜¤" in prompt:
            print("âœ… ëª¨ë“œ: ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")

        print(f"{'='*60}\n")

        # Mock ì‘ë‹µ
        return """
## Executive Summary

í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ì˜ ê¸°í›„ ë¦¬ìŠ¤í¬ëŠ” 4ê°€ì§€ SSP ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ í¬ê²Œ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
SSP1-2.6 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” AALì´ 2100ë…„ê¹Œì§€ 45.0%ë¡œ ê°ì†Œí•˜ëŠ” ë°˜ë©´,
SSP5-8.5 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” 92.5%ê¹Œì§€ ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

## Scenario-by-Scenario Analysis

### SSP1-2.6 (ì§€ì†ê°€ëŠ¥ ë°œì „)
AALì€ 2024ë…„ 52.9%ì—ì„œ 2100ë…„ 45.0%ë¡œ **14.9% ê°ì†Œ**í•©ë‹ˆë‹¤.
ì¹œí™˜ê²½ ì •ì±…ê³¼ êµ­ì œ í˜‘ë ¥ìœ¼ë¡œ ì˜¨ì‹¤ê°€ìŠ¤ ê°ì¶•ì´ ì„±ê³µí•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤.

### SSP2-4.5 (ì¤‘ê°„ ê²½ë¡œ)
AALì€ 2024ë…„ 52.9%ì—ì„œ 2100ë…„ 68.1%ë¡œ **28.7% ì¦ê°€**í•©ë‹ˆë‹¤.
í˜„ì¬ ì¶”ì„¸ê°€ ìœ ì§€ë˜ë©° ì ì§„ì ì¸ ê¸°í›„ ëŒ€ì‘ì´ ì´ë£¨ì–´ì§€ëŠ” ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤.

### SSP3-7.0 (ì§€ì—­ ê²½ìŸ)
AALì€ 2024ë…„ 52.9%ì—ì„œ 2100ë…„ 78.5%ë¡œ **48.4% ì¦ê°€**í•©ë‹ˆë‹¤.
êµ­ê°€ ê°„ ê²½ìŸì´ ì‹¬í™”ë˜ê³  ê¸°í›„ ëŒ€ì‘ì´ ë¯¸í¡í•œ ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤.

### SSP5-8.5 (í™”ì„ì—°ë£Œ ì§‘ì•½)
AALì€ 2024ë…„ 52.9%ì—ì„œ 2100ë…„ 92.5%ë¡œ **74.9% ì¦ê°€**í•©ë‹ˆë‹¤.
í™”ì„ì—°ë£Œ ì˜ì¡´ì´ ì§€ì†ë˜ëŠ” ìµœì•…ì˜ ê¸°í›„ë³€í™” ì‹œë‚˜ë¦¬ì˜¤ì…ë‹ˆë‹¤.

## Comparative Analysis

**ì‹œë‚˜ë¦¬ì˜¤ ê°„ AAL ì°¨ì´:**
- ìµœì„  ì‹œë‚˜ë¦¬ì˜¤(SSP1-2.6): 45.0%
- ìµœì•… ì‹œë‚˜ë¦¬ì˜¤(SSP5-8.5): 92.5%
- **ì°¨ì´: 47.5%p** (2ë°° ì´ìƒ)

**ì£¼ìš” ì¸ì‚¬ì´íŠ¸:**
- 2030ë…„ê¹Œì§€ëŠ” ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ AAL ì°¨ì´ê°€ í¬ì§€ ì•ŠìŒ
- 2050ë…„ ì´í›„ ì‹œë‚˜ë¦¬ì˜¤ ê°„ ê²©ì°¨ê°€ ê¸‰ê²©íˆ ë²Œì–´ì§
- SSP5-8.5 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” 2100ë…„ AALì´ 90%ë¥¼ ì´ˆê³¼

## Strategic Recommendations

**Top 3 ìš°ì„ ìˆœìœ„:**
1. ë‹¨ê¸°(2025-2030): ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„ ê¸°ë³¸ íšŒë³µë ¥ êµ¬ì¶•
2. ì¤‘ê¸°(2030-2050): ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë‹ˆí„°ë§ ë° ì ì‘ ì „ëµ ì¡°ì •
3. ì¥ê¸°(2050+): ìµœì•… ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„ ë³€í˜ì  ëŒ€ì‘ ì¤€ë¹„

**íˆ¬ì ë¡œë“œë§µ:**
- ë‹¨ê¸°: 10-20ì–µì› (ëª¨ë‹ˆí„°ë§, ê¸´ê¸‰ ëŒ€ì‘)
- ì¤‘ê¸°: 50-100ì–µì› (ì¸í”„ë¼ ê°•í™”)
- ì¥ê¸°: 200-500ì–µì› (ì‚¬ì—…ì¥ ì¬ë°°ì¹˜ ê²€í† )

## Stakeholder Messaging

"ìš°ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ëŠ” ë‹¤ì–‘í•œ ê¸°í›„ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ íšŒë³µë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.
ìµœì•…ì˜ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œë„ ì²´ê³„ì ì¸ ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•˜ì—¬ ë¦¬ìŠ¤í¬ë¥¼ ê´€ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤."
"""


class RealLLM:
    """ì‹¤ì œ OpenAI LLM"""
    def __init__(self):
        from openai import AsyncOpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
        self.client = AsyncOpenAI(api_key=api_key)

    async def ainvoke(self, prompt):
        print(f"\nğŸš€ OpenAI API í˜¸ì¶œ ì¤‘...")
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an ESG report analyst specializing in TCFD disclosures."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        result = response.choices[0].message.content
        print(f"âœ… API ì‘ë‹µ ì™„ë£Œ ({len(result)} ê¸€ì)")
        return result


async def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸ§ª Node 2-A: Scenario Analysis v2 í…ŒìŠ¤íŠ¸")
    print("="*80)

    # ì ˆëŒ€ importë¡œ ë³€ê²½ (í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€)
    project_root = Path(__file__).parent.parent.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

    from ai_agent.agents.tcfd_report.node_2a_scenario_analysis_v2 import ScenarioAnalysisNode

    # LLM í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    use_real = os.getenv("USE_REAL_LLM", "false").lower() == "true"

    if use_real:
        print("\nğŸš€ ì‹¤ì œ OpenAI API ì‚¬ìš©")
        try:
            llm = RealLLM()
        except Exception as e:
            print(f"âŒ OpenAI ì„¤ì • ì‹¤íŒ¨: {e}")
            print("Mock LLMìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            llm = MockLLM()
    else:
        print("\nğŸ¤– Mock LLM ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)")
        llm = MockLLM()

    # Node 2-A ì´ˆê¸°í™”
    node = ScenarioAnalysisNode(llm_client=llm)

    # ìƒ˜í”Œ ë°ì´í„°
    sites_data = create_sample_sites_data()
    report_template = create_sample_report_template()

    print("\nğŸ“„ ì…ë ¥ ë°ì´í„°:")
    print(f"  - ì‚¬ì—…ì¥ ê°œìˆ˜: {len(sites_data)}")
    print(f"  - í…œí”Œë¦¿ í•„ë“œ ê°œìˆ˜: {len(report_template)}")

    # Node 2-A ì‹¤í–‰
    print("\n" + "="*80)
    print("â–¶ Node 2-A ì‹¤í–‰")
    print("="*80)

    result = await node.execute(
        sites_data=sites_data,
        report_template=report_template,
        agent_guideline=None
    )

    # ê²°ê³¼ í™•ì¸
    scenarios = result["scenarios"]
    scenario_table = result["scenario_table"]
    scenario_text_block = result["scenario_text_block"]
    comparison_analysis = result["comparison_analysis"]

    print("\nâœ… ì‹¤í–‰ ì™„ë£Œ!")
    print(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
    print(f"  - ì‹œë‚˜ë¦¬ì˜¤ ê°œìˆ˜: {len(scenarios)}")
    print(f"  - TableBlock íƒ€ì…: {scenario_table.get('type')}")
    print(f"  - TextBlock íƒ€ì…: {scenario_text_block.get('type')}")
    print(f"  - ë¹„êµ ë¶„ì„ ê¸¸ì´: {len(comparison_analysis)} ê¸€ì")

    # ì‹œë‚˜ë¦¬ì˜¤ë³„ AAL ì¶œë ¥
    print(f"\nğŸ” ì‹œë‚˜ë¦¬ì˜¤ë³„ AAL:")
    for scenario_key, data in scenarios.items():
        aal_start = data.get("aal_values", [0])[0]
        aal_end = data.get("aal_values", [0])[-1]
        change_rate = data.get("change_rate", 0)
        name_kr = data.get("scenario_name_kr", "")

        print(f"  {scenario_key.upper()} ({name_kr}):")
        print(f"    2024: {aal_start}% â†’ 2100: {aal_end}% ({change_rate:+.1f}%)")

    # TableBlock ë¯¸ë¦¬ë³´ê¸°
    print(f"\nğŸ“‹ TableBlock ë¯¸ë¦¬ë³´ê¸°:")
    table_data = scenario_table.get("data", {})
    print(f"  ì œëª©: {scenario_table.get('title')}")
    print(f"  í—¤ë”: {table_data.get('headers')}")
    print(f"  í–‰ ê°œìˆ˜: {len(table_data.get('rows', []))}")

    # TextBlock ë¯¸ë¦¬ë³´ê¸°
    print(f"\nğŸ“ TextBlock ë¯¸ë¦¬ë³´ê¸°:")
    print(f"  ì†Œì œëª©: {scenario_text_block.get('subheading')}")
    content = scenario_text_block.get('content', '')
    print(f"  ë‚´ìš© ê¸¸ì´: {len(content)} ê¸€ì")
    print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {content[:200]}...")

    # ë¹„êµ ë¶„ì„ ë¯¸ë¦¬ë³´ê¸°
    print(f"\nğŸ“Š ë¹„êµ ë¶„ì„ ë¯¸ë¦¬ë³´ê¸°:")
    print(f"{comparison_analysis[:500]}...")

    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).parent / "test_output"
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"node2a_result_{timestamp}.json"

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")

    print("\n" + "="*80)
    print("âœ… Node 2-A í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)

    # ì‹¤ì œ LLM ì‚¬ìš© ì•ˆë‚´
    if not use_real:
        print("\nğŸ’¡ ì‹¤ì œ OpenAI APIë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:")
        print("   1. set OPENAI_API_KEY=your_key")
        print("   2. set USE_REAL_LLM=true")
        print("   3. python -m ai_agent.agents.tcfd_report.test_node2a_simple")


if __name__ == "__main__":
    asyncio.run(main())
