'''
íŒŒì¼ëª…: additional_data_loader.py
ì‘ì„±ì¼: 2025-12-16
ë²„ì „: v05 (Key-Value íŒŒì‹± + data_category ì œê±°)
íŒŒì¼ ê°œìš”: ì¶”ê°€ ë°ì´í„° (Excel) ETL ë¡œë”

ë³€ê²½ ë‚´ì—­ (v05):
    - Excel íŒŒì‹± ë°©ì‹ ê°œì„ : í…ìŠ¤íŠ¸ ë¤í”„ â†’ Key-Value êµ¬ì¡°
    - íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìë™ í´ë°± (Fallback ëª¨ë“œ)
    - data_category í•„ë“œ ì œê±° (metadataë¡œ ì´ë™)

================================================================================
[ ì…ë ¥ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ]
================================================================================

1. load_from_scratch_folder() - scratch í´ë”ì—ì„œ Excel íŒŒì¼ â†’ DB ì ì¬
   ì…ë ¥:
       - scratch_folder: str (scratch í´ë” ê²½ë¡œ)
         ì˜ˆ: "/path/to/scratch"

   í´ë” êµ¬ì¡°:
       scratch/
       â”œâ”€â”€ 22222222-2222-2222-2222-222222222222/   â† í´ë”ëª… = site_id
       â”‚   â”œâ”€â”€ ì—ë„ˆì§€_ì‚¬ìš©ëŸ‰.xlsx
       â”‚   â””â”€â”€ ì „ë ¥_ì‚¬ìš©ëŸ‰.xlsx
       â””â”€â”€ 44444444-4444-4444-4444-444444444444/
           â””â”€â”€ ...

   ì¶œë ¥:
       - Dict: ì ì¬ ê²°ê³¼
         {
           "total_files": 5,
           "success_count": 5,
           "failed_count": 0,
           "results": [...]
         }

2. load_and_save() - ë‹¨ì¼ Excel íŒŒì¼ â†’ DB ì ì¬
   ì…ë ¥:
       - file_path: str (Excel íŒŒì¼ ê²½ë¡œ, í•„ìˆ˜)
       - site_id: str (ì‚¬ì—…ì¥ UUID, í•„ìˆ˜)
       - category: str (ì„ íƒ, metadataì— ì €ì¥ë¨)

3. fetch_all_for_site() - DBì—ì„œ ì‚¬ì´íŠ¸ë³„ ì¶”ê°€ ë°ì´í„° ì¡°íšŒ
   ì…ë ¥:
       - site_id: str (ì‚¬ì—…ì¥ UUID, í•„ìˆ˜)

   ì¶œë ¥:
       - Dict[str, List]: ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„°

================================================================================
[ DB í…Œì´ë¸” ]
================================================================================

site_additional_data (datawarehouse DB):
    - PK: id (UUID)
    - ì£¼ìš” ì»¬ëŸ¼:
        - site_id: UUID (FK â†’ sites.id)
        - raw_text: text (PDF ì¶”ì¶œìš©)
        - structured_data: JSONB (Key-Value íŒŒì‹±ëœ Excel ë°ì´í„°)
        - file_content: JSONB (íŒŒì¼ ë‚´ìš©)
        - metadata: JSONB (íŒŒì¼ ë©”íƒ€ ì •ë³´, ì¹´í…Œê³ ë¦¬ í¬í•¨)
        - uploaded_by: uuid
        - uploaded_at: timestamp
        - expires_at: timestamp

    ì£¼ì˜: data_category ì»¬ëŸ¼ ì œê±°ë¨ (metadata.inferred_categoryë¡œ ëŒ€ì²´)

================================================================================
[ íŒŒì‹± ë°©ì‹ ]
================================================================================

1. Structured ëª¨ë“œ (ê¸°ë³¸):
    - ì²« í–‰ì„ í—¤ë”ë¡œ ì¸ì‹
    - ê° í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
    - JSON í¬ê¸° ìµœì í™”

2. Fallback ëª¨ë“œ (íŒŒì‹± ì‹¤íŒ¨ ì‹œ):
    - í…ìŠ¤íŠ¸ ë¤í”„ ë°©ì‹ ì‚¬ìš©
    - ëª¨ë“  ì…€ ê°’ì„ " | "ë¡œ ì—°ê²°

3. ì˜ˆì™¸ ì²˜ë¦¬:
    - ë¹ˆ í—¤ë” â†’ "Column_N" ìë™ ìƒì„±
    - ì¤‘ë³µ í—¤ë” â†’ "_2", "_3" ì ‘ë¯¸ì‚¬ ì¶”ê°€
    - ë¹ˆ í–‰ ìë™ ìŠ¤í‚µ

================================================================================
[ ì¹´í…Œê³ ë¦¬ ìë™ ì¶”ë¡  ê·œì¹™ ]
================================================================================

íŒŒì¼ëª…ì— í¬í•¨ëœ í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (metadata.inferred_category):
    - "ì „ë ¥" ë˜ëŠ” "power" â†’ "power"
    - "ì—ë„ˆì§€" ë˜ëŠ” "energy" â†’ "energy"
    - "ë³´í—˜" ë˜ëŠ” "insurance" â†’ "insurance"
    - "ê±´ë¬¼" ë˜ëŠ” "building" â†’ "building"
    - "ìì‚°" ë˜ëŠ” "asset" â†’ "asset"
    - "ì‹œì„¤" ë˜ëŠ” "facility" â†’ "facility"
    - ê·¸ ì™¸ â†’ "other"

================================================================================
'''

from typing import Dict, Any, List, Optional
import logging
import os
import re
from datetime import datetime
from openpyxl import load_workbook
from pathlib import Path

# DatabaseManager ì„í¬íŠ¸
try:
    from ...utils.database import DatabaseManager
except ImportError:
    DatabaseManager = None
    print("âš ï¸ DatabaseManagerë¥¼ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

logger = logging.getLogger(__name__)


class AdditionalDataLoader:
    """
    ì¶”ê°€ ë°ì´í„° ETL ë¡œë” (Excel â†’ DB ì ì¬)

    ì—­í• :
        1. scratch í´ë” ìŠ¤ìº” (í´ë”ëª… = site_id)
        2. Excel íŒŒì¼ ì½ê¸° (ë²”ìš© í…ìŠ¤íŠ¸ ë¤í”„)
        3. site_additional_data í…Œì´ë¸”ì— ì ì¬

    ì‚¬ìš© ì˜ˆì‹œ:
        loader = AdditionalDataLoader(db_url="postgresql://...")

        # ë°©ë²• 1: scratch í´ë” ì „ì²´ ì ì¬
        loader.load_from_scratch_folder("/path/to/scratch")

        # ë°©ë²• 2: ë‹¨ì¼ íŒŒì¼ ì ì¬
        loader.load_and_save("path/to/file.xlsx", site_id="uuid-...")
    """

    def __init__(self, db_url: Optional[str] = None, db_manager=None):
        """
        ì´ˆê¸°í™”

        Args:
            db_url: Datawarehouse DB URL (site_additional_data í…Œì´ë¸” ì ‘ê·¼ìš©) - DEPRECATED
            db_manager: DatabaseManager ì¸ìŠ¤í„´ìŠ¤ (ê¶Œì¥)
        """
        self.logger = logger

        # DatabaseManager ì´ˆê¸°í™” ë˜ëŠ” ì „ë‹¬ë°›ì€ ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©
        if db_manager:
            # ì „ë‹¬ë°›ì€ DatabaseManager ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© (ê¶Œì¥)
            self.db_manager = db_manager
            self.logger.info("DatabaseManager ì¸ìŠ¤í„´ìŠ¤ ì „ë‹¬ë°›ìŒ (site_additional_data)")
        elif DatabaseManager and db_url:
            # DEPRECATED: URLë¡œ ì´ˆê¸°í™” (í•˜ìœ„ í˜¸í™˜ì„±)
            self.logger.warning("db_url ì‚¬ìš©ì€ deprecatedì…ë‹ˆë‹¤. db_managerë¥¼ ì „ë‹¬í•˜ì„¸ìš”.")
            self.db_manager = None
        else:
            self.db_manager = None
            self.logger.warning("DatabaseManager ì—†ìŒ - DB ì ì¬ ë¹„í™œì„±í™”")

        self.logger.info("AdditionalDataLoader ì´ˆê¸°í™” ì™„ë£Œ")

    # ==========================================================================
    # scratch í´ë” ê¸°ë°˜ ì ì¬ (í´ë”ëª… = site_id)
    # ==========================================================================

    def load_from_scratch_folder(self, scratch_folder: str) -> Dict[str, Any]:
        """
        scratch í´ë” ë‚´ ëª¨ë“  Excel íŒŒì¼ì„ DBì— ì ì¬

        í´ë” êµ¬ì¡°:
            scratch/
            â”œâ”€â”€ {site_id_1}/
            â”‚   â”œâ”€â”€ file1.xlsx
            â”‚   â””â”€â”€ file2.xlsx
            â””â”€â”€ {site_id_2}/
                â””â”€â”€ file3.xlsx

        Args:
            scratch_folder: scratch í´ë” ê²½ë¡œ

        Returns:
            ì ì¬ ê²°ê³¼ ìš”ì•½
        """
        self.logger.info(f"scratch í´ë” ìŠ¤ìº” ì‹œì‘: {scratch_folder}")

        if not os.path.exists(scratch_folder):
            self.logger.error(f"scratch í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {scratch_folder}")
            return {"error": "í´ë” ì—†ìŒ", "total_files": 0}

        results = []
        total_files = 0
        success_count = 0
        failed_count = 0

        # í•˜ìœ„ í´ë” ìˆœíšŒ (í´ë”ëª… = site_id)
        for folder_name in os.listdir(scratch_folder):
            folder_path = os.path.join(scratch_folder, folder_name)

            if not os.path.isdir(folder_path):
                continue

            # í´ë”ëª…ì´ UUID í˜•ì‹ì¸ì§€ í™•ì¸
            site_id = self._extract_site_id_from_folder(folder_name)
            if not site_id:
                self.logger.warning(f"UUID í˜•ì‹ì´ ì•„ë‹Œ í´ë” ìŠ¤í‚µ: {folder_name}")
                continue

            self.logger.info(f"ì‚¬ì—…ì¥ í´ë” ì²˜ë¦¬: {folder_name} â†’ site_id={site_id[:8]}...")

            # í´ë” ë‚´ Excel íŒŒì¼ ì²˜ë¦¬
            for file_name in os.listdir(folder_path):
                if not file_name.endswith(('.xlsx', '.xls')):
                    continue

                file_path = os.path.join(folder_path, file_name)
                total_files += 1

                result = self.load_and_save(file_path, site_id)
                results.append(result)

                if result.get("success"):
                    success_count += 1
                else:
                    failed_count += 1

        summary = {
            "total_files": total_files,
            "success_count": success_count,
            "failed_count": failed_count,
            "deleted_files": sum(1 for r in results if r.get("file_deleted")),
            "results": results
        }

        self.logger.info(
            f"scratch í´ë” ì ì¬ ì™„ë£Œ: {success_count}/{total_files} ì„±ê³µ, "
            f"{summary['deleted_files']}ê°œ íŒŒì¼ ì‚­ì œ"
        )
        return summary

    def _extract_site_id_from_folder(self, folder_name: str) -> Optional[str]:
        """
        í´ë”ëª…ì—ì„œ site_id (UUID) ì¶”ì¶œ

        Args:
            folder_name: í´ë”ëª…

        Returns:
            UUID ë¬¸ìì—´ ë˜ëŠ” None
        """
        # UUID íŒ¨í„´ (8-4-4-4-12)
        uuid_pattern = r'^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$'

        if re.match(uuid_pattern, folder_name):
            return folder_name.lower()  # ì†Œë¬¸ìë¡œ ì •ê·œí™”

        return None

    # ==========================================================================
    # ë‹¨ì¼ íŒŒì¼ ì ì¬
    # ==========================================================================

    def load_and_save(
        self,
        file_path: str,
        site_id: str,
        category: str = None,  # í˜¸í™˜ì„± ìœ ì§€ (metadataë¡œ ì €ì¥)
        auto_cleanup: bool = True  # ìë™ ì‚­ì œ í”Œë˜ê·¸ (ì„±ê³µ ì‹œ íŒŒì¼ ì‚­ì œ)
    ) -> Dict[str, Any]:
        """
        Excel íŒŒì¼ì„ ì½ì–´ì„œ site_additional_data í…Œì´ë¸”ì— ì ì¬

        Args:
            file_path: Excel íŒŒì¼ ê²½ë¡œ
            site_id: ì‚¬ì—…ì¥ UUID
            category: ë°ì´í„° ì¹´í…Œê³ ë¦¬ (ì„ íƒ, metadataì— ì €ì¥ë¨)

        Returns:
            ì ì¬ ê²°ê³¼ ì •ë³´
        """
        file_name = Path(file_path).name
        self.logger.info(f"Excel â†’ DB ì ì¬: {file_name}")

        if not self.db_manager:
            self.logger.error("DB ì—°ê²° ì—†ìŒ - ì ì¬ ë¶ˆê°€")
            return {"success": False, "error": "DB ì—°ê²° ì—†ìŒ", "file_name": file_name}

        try:
            # 1. Excel íŒŒì¼ì„ Key-Value êµ¬ì¡°ë¡œ íŒŒì‹±
            data = self._universal_excel_dump(file_path)

            if 'error' in data:
                self.logger.error(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {data['error']}")
                return {"success": False, "error": data['error'], "file_name": file_name}

            # 2. ì¹´í…Œê³ ë¦¬ ì¶”ë¡  (metadataìš©)
            if not category:
                category = self._infer_category(file_name)

            # 3. ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                'source': 'AdditionalDataLoader',
                'file_name': file_name,
                'inferred_category': category,  # ì¹´í…Œê³ ë¦¬ëŠ” metadataì— ì €ì¥
                'parsing_method': data.get('parsing_method', 'unknown'),
                'loaded_at': datetime.now().isoformat(),
                'sheet_count': len(data.get('sheets', [])),
                'total_rows': sum(s.get('row_count', 0) for s in data.get('sheets', []))
            }

            # 4. DBì— ì €ì¥
            self.db_manager.save_additional_data(
                site_id=site_id,
                structured_data=data,
                metadata=metadata
            )

            self.logger.info(f"âœ… DB ì ì¬ ì™„ë£Œ: {file_name} â†’ site_id={site_id[:8]}..., parsing={data.get('parsing_method')}")

            # 5. Auto cleanup (ì„±ê³µ ì‹œ íŒŒì¼ ì‚­ì œ)
            cleanup_status = None
            if auto_cleanup:
                cleanup_status = self.cleanup_file(file_path)
                if cleanup_status:
                    self.logger.info(f"ğŸ—‘ï¸ íŒŒì¼ ìë™ ì‚­ì œ ì™„ë£Œ: {file_path}")
                else:
                    self.logger.warning(f"âš ï¸ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path}")

            return {
                "success": True,
                "site_id": site_id,
                "category": category,  # í˜¸í™˜ì„± ìœ ì§€
                "parsing_method": data.get('parsing_method'),
                "file_name": file_name,
                "sheet_count": len(data.get('sheets', [])),
                "total_rows": metadata['total_rows'],
                "file_deleted": cleanup_status  # ì‚­ì œ ì—¬ë¶€
            }

        except Exception as e:
            self.logger.error(f"DB ì ì¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "file_name": file_name}

    def _universal_excel_dump(self, file_path: str) -> Dict[str, Any]:
        """
        Excelì„ Key-Value êµ¬ì¡°ë¡œ íŒŒì‹± (í´ë°±: í…ìŠ¤íŠ¸ ë¤í”„)

        íŒŒì‹± ì „ëµ:
            1. ì²« í–‰ì„ í—¤ë”ë¡œ ì¸ì‹
            2. ê° í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            3. íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë¤í”„ë¡œ í´ë°±

        Args:
            file_path: Excel íŒŒì¼ ê²½ë¡œ

        Returns:
            íŒŒì‹±ëœ ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (structured ë˜ëŠ” fallback ëª¨ë“œ)
        """
        result = {
            'file_name': Path(file_path).name,
            'uploaded_at': datetime.now().isoformat(),
            'sheets': [],
            'parsing_method': 'unknown'
        }

        try:
            wb = load_workbook(file_path, data_only=True)

            for sheet_name in wb.sheetnames:
                ws = wb[sheet_name]

                # ì‹œíŠ¸ íŒŒì‹± ì‹œë„
                sheet_data = self._parse_sheet_structured(ws, sheet_name)

                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í´ë°± ëª¨ë“œ
                if sheet_data.get('parsing_failed'):
                    sheet_data = self._parse_sheet_fallback(ws, sheet_name)
                    result['parsing_method'] = 'fallback'
                else:
                    result['parsing_method'] = 'structured'

                result['sheets'].append(sheet_data)

            wb.close()

        except Exception as e:
            self.logger.error(f"Excel íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            result['error'] = str(e)
            result['sheets'] = []
            result['parsing_method'] = 'error'

        return result

    def _parse_sheet_structured(self, ws, sheet_name: str) -> Dict[str, Any]:
        """
        ì‹œíŠ¸ë¥¼ Key-Value êµ¬ì¡°ë¡œ íŒŒì‹±

        Args:
            ws: openpyxl Worksheet ê°ì²´
            sheet_name: ì‹œíŠ¸ëª…

        Returns:
            íŒŒì‹±ëœ ì‹œíŠ¸ ë°ì´í„° ë˜ëŠ” ì‹¤íŒ¨ í”Œë˜ê·¸
        """
        try:
            all_rows = list(ws.iter_rows(values_only=True))

            if not all_rows or len(all_rows) < 2:
                # ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í—¤ë”ë§Œ ìˆìœ¼ë©´ ì‹¤íŒ¨
                return {'parsing_failed': True}

            # Step 1: ì²« í–‰ì„ í—¤ë”ë¡œ ê°„ì£¼
            header_row = all_rows[0]
            headers = []
            for idx, cell_value in enumerate(header_row):
                if cell_value is None or str(cell_value).strip() == '':
                    headers.append(f'Column_{idx + 1}')  # ë¹ˆ í—¤ë”ëŠ” ìë™ ì´ë¦„
                else:
                    headers.append(str(cell_value).strip())

            # ì¤‘ë³µ í—¤ë” ì²˜ë¦¬ (ê°™ì€ ì´ë¦„ì— _2, _3 ì¶”ê°€)
            seen = {}
            for i, header in enumerate(headers):
                if header in seen:
                    seen[header] += 1
                    headers[i] = f"{header}_{seen[header]}"
                else:
                    seen[header] = 1

            # Step 2: ë°ì´í„° í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            data_rows = []
            for row_values in all_rows[1:]:
                # ì™„ì „íˆ ë¹ˆ í–‰ì€ ìŠ¤í‚µ
                if not any(v is not None and str(v).strip() != '' for v in row_values):
                    continue

                row_dict = {}
                for idx, value in enumerate(row_values):
                    if idx < len(headers):
                        # ê°’ íƒ€ì… ìë™ ë³€í™˜ (ìˆ«ìëŠ” ìˆ«ìë¡œ ìœ ì§€)
                        if value is None:
                            row_dict[headers[idx]] = None
                        elif isinstance(value, (int, float)):
                            row_dict[headers[idx]] = value
                        else:
                            row_dict[headers[idx]] = str(value).strip()

                data_rows.append(row_dict)

            # Step 3: ê²°ê³¼ ë°˜í™˜
            return {
                'name': sheet_name,
                'headers': headers,
                'data': data_rows,
                'row_count': len(data_rows),
                'parsing_method': 'structured'
            }

        except Exception as e:
            self.logger.warning(f"ì‹œíŠ¸ '{sheet_name}' íŒŒì‹± ì‹¤íŒ¨: {e}, í´ë°± ëª¨ë“œë¡œ ì „í™˜")
            return {'parsing_failed': True}

    def _parse_sheet_fallback(self, ws, sheet_name: str) -> Dict[str, Any]:
        """
        í´ë°± ëª¨ë“œ: í…ìŠ¤íŠ¸ ë¤í”„ ë°©ì‹

        Args:
            ws: openpyxl Worksheet ê°ì²´
            sheet_name: ì‹œíŠ¸ëª…

        Returns:
            í…ìŠ¤íŠ¸ ë¤í”„ëœ ì‹œíŠ¸ ë°ì´í„°
        """
        rows = []
        for row in ws.iter_rows():
            row_values = [str(cell.value) if cell.value is not None else '' for cell in row]
            # ì™„ì „íˆ ë¹ˆ í–‰ì€ ìŠ¤í‚µ
            if any(v.strip() for v in row_values):
                rows.append(' | '.join(row_values))

        return {
            'name': sheet_name,
            'row_count': len(rows),
            'content': '\n'.join(rows),
            'parsing_method': 'fallback'
        }

    def _infer_category(self, file_name: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ """
        file_lower = file_name.lower()

        if 'ì „ë ¥' in file_lower or 'power' in file_lower:
            return 'power'
        elif 'ì—ë„ˆì§€' in file_lower or 'energy' in file_lower:
            return 'energy'
        elif 'ë³´í—˜' in file_lower or 'insurance' in file_lower:
            return 'insurance'
        elif 'ê±´ë¬¼' in file_lower or 'building' in file_lower:
            return 'building'
        elif 'ìì‚°' in file_lower or 'asset' in file_lower:
            return 'asset'
        elif 'ì‹œì„¤' in file_lower or 'facility' in file_lower:
            return 'facility'
        else:
            return 'other'

    # ==========================================================================
    # DB ì¡°íšŒ ë©”ì„œë“œ (Agentê°€ ì‚¬ìš©)
    # ==========================================================================

    def fetch_from_db(
        self,
        site_id: str,
        category: str = None  # í˜¸í™˜ì„± ìœ ì§€ (metadata í•„í„°ë§)
    ) -> List[Dict[str, Any]]:
        """
        site_additional_data í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¡°íšŒ

        Args:
            site_id: ì‚¬ì—…ì¥ UUID
            category: ë°ì´í„° ì¹´í…Œê³ ë¦¬ (ì„ íƒ, metadataì—ì„œ í•„í„°ë§)

        Returns:
            ì¡°íšŒëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not self.db_manager:
            self.logger.warning("DB ì—°ê²° ì—†ìŒ - ì¡°íšŒ ë¶ˆê°€")
            return []

        try:
            # data_category í•„ë“œ ì œê±°ë¨, site_idë§Œìœ¼ë¡œ ì¡°íšŒ
            results = self.db_manager.fetch_additional_data(site_id=site_id)

            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (metadataì—ì„œ)
            if category:
                filtered_results = []
                for item in results:
                    metadata = item.get('metadata', {})
                    if metadata.get('inferred_category') == category:
                        filtered_results.append(item)
                results = filtered_results

            self.logger.info(f"DB ì¡°íšŒ ì™„ë£Œ: site_id={site_id[:8]}..., {len(results)}ê°œ ë°ì´í„°")
            return results

        except Exception as e:
            self.logger.error(f"DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def fetch_all_for_site(self, site_id: str) -> Dict[str, Any]:
        """
        íŠ¹ì • ì‚¬ì—…ì¥ì˜ ëª¨ë“  ì¶”ê°€ ë°ì´í„°ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬í•˜ì—¬ ë°˜í™˜

        Args:
            site_id: ì‚¬ì—…ì¥ UUID

        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
            {
                "energy": [...],
                "power": [...],
                ...
            }
        """
        all_data = self.fetch_from_db(site_id)

        # metadataì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œí•˜ì—¬ ì •ë¦¬
        categorized = {}
        for item in all_data:
            metadata = item.get('metadata', {})
            cat = metadata.get('inferred_category', 'other')

            if cat not in categorized:
                categorized[cat] = []
            categorized[cat].append(item)

        return categorized

    # ==========================================================================
    # ìœ í‹¸ë¦¬í‹°
    # ==========================================================================

    def cleanup_file(self, file_path: str) -> bool:
        """
        Excel íŒŒì¼ ì‚­ì œ (ë¶„ì„ ì™„ë£Œ í›„ ì •ë¦¬)

        Args:
            file_path: ì‚­ì œí•  Excel íŒŒì¼ ê²½ë¡œ

        Returns:
            ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            if os.path.exists(file_path):
                os.remove(file_path)
                self.logger.info(f"âœ… Excel íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
                return True
            else:
                self.logger.warning(f"âš ï¸ Excel íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {file_path}")
                return False
        except Exception as e:
            self.logger.error(f"âŒ Excel íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file_path}, ì˜¤ë¥˜: {e}")
            return False
