"""
Node 4: Validator & Refiner v2
ìµœì¢… ìˆ˜ì •ì¼: 2025-12-15
ë²„ì „: v2.0

ê°œìš”:
    Node 4: TCFD ê²€ì¦ ë° í’ˆì§ˆ ê´€ë¦¬ ë…¸ë“œ

    - TCFD 7ëŒ€ ì›ì¹™ ê²€ì¦: Relevant, Specific, Clear, Consistent, Comparable, Reliable, Timely
    - ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    - í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ
    - Critical ì´ìŠˆ ë°œìƒ ì‹œ 1íšŒ ì¬ìƒì„± (ë¬´í•œ ë£¨í”„ ë°©ì§€)

ì£¼ìš” ê¸°ëŠ¥:
    1. í•„ìˆ˜ ì„¹ì…˜ ì™„ì„±ë„ ê²€ì¦
    2. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ (AAL í•©ê³„, ë¦¬ìŠ¤í¬ ìˆœìœ„ ë“±)
    3. TCFD 7ëŒ€ ì›ì¹™ ê²€ì¦
    4. í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ (0-100ì )
    5. Critical ì´ìŠˆ ë°œìƒ ì‹œ í”¼ë“œë°± ì œê³µ

ì…ë ¥:
    - strategy: Dict (Node 3 ì¶œë ¥)
    - report_template: Dict (Node 1 ì¶œë ¥)
    - scenario_analysis: Dict (Node 2-A ì¶œë ¥)
    - impact_analyses: List[Dict] (Node 2-B ì¶œë ¥)

ì¶œë ¥:
    - validation_result: Dict (is_valid, quality_score, issues, feedback)
    - validated: bool
"""

import json
from typing import Dict, Any, List, Optional


class ValidatorNode:
    """
    Node 4: Validator & Refiner ë…¸ë“œ v2

    ì—­í• :
        - TCFD ë³´ê³ ì„œ í’ˆì§ˆ ê²€ì¦
        - 7ëŒ€ ì›ì¹™ ì¤€ìˆ˜ ì—¬ë¶€ í™•ì¸
        - ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
        - í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ

    ì˜ì¡´ì„±:
        - Node 3 (Strategy Section) ì™„ë£Œ í•„ìˆ˜
        - Node 2-A, 2-B (ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ìš©)
    """

    def __init__(self, llm_client=None):
        """
        Node ì´ˆê¸°í™”

        Args:
            llm_client: ainvoke ë©”ì„œë“œë¥¼ ì§€ì›í•˜ëŠ” LLM í´ë¼ì´ì–¸íŠ¸ (optional)
        """
        self.llm = llm_client

        # TCFD 7ëŒ€ ì›ì¹™
        self.tcfd_principles = [
            "Relevant",      # ê´€ë ¨ì„±: íˆ¬ììì—ê²Œ ìœ ìš©í•œ ì •ë³´
            "Specific",      # êµ¬ì²´ì„±: ì •ëŸ‰ì  ë°ì´í„° í¬í•¨
            "Clear",         # ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´
            "Consistent",    # ì¼ê´€ì„±: ë‚´ë¶€ ë°ì´í„° ì¼ì¹˜
            "Comparable",    # ë¹„êµê°€ëŠ¥ì„±: ì‹œê°„/ì¡°ì§ê°„ ë¹„êµ
            "Reliable",      # ì‹ ë¢°ì„±: ê²€ì¦ ê°€ëŠ¥í•œ ë°ì´í„°
            "Timely"         # ì ì‹œì„±: ìµœì‹  ì •ë³´ ë°˜ì˜
        ]

    async def execute(
        self,
        strategy_section: Dict,
        report_template: Optional[Dict] = None,
        scenario_analysis: Optional[Dict] = None,
        impact_analyses: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

        Args:
            strategy_section: Node 3 ì¶œë ¥ (Strategy ì„¹ì…˜)
            report_template: Node 1 ì¶œë ¥ (optional, ë°ì´í„° ê²€ì¦ìš©)
            scenario_analysis: Node 2-A ì¶œë ¥ (optional, ë°ì´í„° ê²€ì¦ìš©)
            impact_analyses: Node 2-B ì¶œë ¥ (optional, ë°ì´í„° ê²€ì¦ìš©)

        Returns:
            Dict: ê²€ì¦ ê²°ê³¼
        """
        print("\n" + "="*80)
        print("â–¶ Node 4: Validator ê²€ì¦ ì‹œì‘")
        print("="*80)

        # 1. í•„ìˆ˜ ì„¹ì…˜ ì²´í¬
        print("\n[Step 1/4] í•„ìˆ˜ ìš”ì†Œ ì™„ì„±ë„ ê²€ì¦...")
        completeness_issues = self._check_completeness(strategy_section)
        print(f"  âœ… ì™„ì„±ë„ ê²€ì¦ ì™„ë£Œ ({len(completeness_issues)}ê°œ ì´ìŠˆ)")

        # 2. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
        print("\n[Step 2/4] ë°ì´í„° ì¼ê´€ì„± ê²€ì¦...")
        consistency_issues = self._check_data_consistency(
            strategy_section,
            scenario_analysis,
            impact_analyses
        )
        print(f"  âœ… ì¼ê´€ì„± ê²€ì¦ ì™„ë£Œ ({len(consistency_issues)}ê°œ ì´ìŠˆ)")

        # 3. TCFD 7ëŒ€ ì›ì¹™ ê²€ì¦
        print("\n[Step 3/4] TCFD 7ëŒ€ ì›ì¹™ ê²€ì¦...")
        principle_scores = self._check_tcfd_principles(strategy_section)
        print(f"  âœ… ì›ì¹™ ê²€ì¦ ì™„ë£Œ")

        # 4. í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ
        print("\n[Step 4/4] í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ...")
        all_issues = completeness_issues + consistency_issues
        quality_score = self._calculate_quality_score(all_issues, principle_scores)
        print(f"  âœ… í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")

        # ê²€ì¦ ê²°ê³¼ ì¡°ë¦½
        is_valid = len([i for i in all_issues if i["severity"] == "critical"]) == 0
        validation_result = {
            "is_valid": is_valid,
            "quality_score": quality_score,
            "issues": all_issues,
            "principle_scores": principle_scores,
            "feedback": self._generate_feedback(all_issues, is_valid)
        }

        print("\n" + "="*80)
        if is_valid:
            print(f"âœ… Node 4: ê²€ì¦ í†µê³¼ (í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f})")
        else:
            print(f"âš ï¸  Node 4: Critical ì´ìŠˆ ë°œê²¬ ({len([i for i in all_issues if i['severity'] == 'critical'])}ê±´)")
        print("="*80)

        return {
            "validation_result": validation_result,
            "validated": is_valid
        }

    def _check_completeness(self, strategy_section: Dict) -> List[Dict]:
        """
        í•„ìˆ˜ ìš”ì†Œ ì™„ì„±ë„ ê²€ì¦

        Args:
            strategy_section: Node 3 ì¶œë ¥

        Returns:
            List[Dict]: ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
        """
        issues = []

        # 1. í•„ìˆ˜ í•„ë“œ ì²´í¬
        required_fields = ["section_id", "title", "blocks"]
        for field in required_fields:
            if field not in strategy_section:
                issues.append({
                    "severity": "critical",
                    "type": "completeness",
                    "field": field,
                    "message": f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}"
                })

        # 2. ë¸”ë¡ ê°œìˆ˜ ì²´í¬ (ìµœì†Œ 5ê°œ ì´ìƒ í•„ìš”)
        blocks = strategy_section.get("blocks", [])
        if len(blocks) < 5:
            issues.append({
                "severity": "warning",
                "type": "completeness",
                "field": "blocks",
                "message": f"ë¸”ë¡ ê°œìˆ˜ ë¶€ì¡±: {len(blocks)}ê°œ (ìµœì†Œ 5ê°œ ê¶Œì¥)"
            })

        # 3. Executive Summary ì¡´ì¬ ì—¬ë¶€
        has_exec_summary = False
        for block in blocks:
            if block.get("subheading") == "Executive Summary":
                has_exec_summary = True
                # Executive Summary ê¸¸ì´ ì²´í¬
                content = block.get("content", "")
                if len(content) < 200:
                    issues.append({
                        "severity": "warning",
                        "type": "completeness",
                        "field": "executive_summary",
                        "message": f"Executive Summaryê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(content)} ê¸€ì, ìµœì†Œ 200 ê¸€ì ê¶Œì¥)"
                    })
                break

        if not has_exec_summary:
            issues.append({
                "severity": "critical",
                "type": "completeness",
                "field": "executive_summary",
                "message": "Executive Summary ëˆ„ë½"
            })

        # 4. HeatmapTableBlock ì¡´ì¬ ì—¬ë¶€
        has_heatmap = False
        for block in blocks:
            if block.get("type") == "heatmap_table":
                has_heatmap = True
                break

        if not has_heatmap:
            issues.append({
                "severity": "warning",
                "type": "completeness",
                "field": "heatmap_table",
                "message": "HeatmapTableBlock ëˆ„ë½ (ê¶Œì¥)"
            })

        return issues

    def _check_data_consistency(
        self,
        strategy_section: Dict,
        scenario_analysis: Optional[Dict],
        impact_analyses: Optional[List[Dict]]
    ) -> List[Dict]:
        """
        ë°ì´í„° ì¼ê´€ì„± ê²€ì¦

        Args:
            strategy_section: Node 3 ì¶œë ¥
            scenario_analysis: Node 2-A ì¶œë ¥ (optional)
            impact_analyses: Node 2-B ì¶œë ¥ (optional)

        Returns:
            List[Dict]: ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
        """
        issues = []

        # 1. HeatmapTableê³¼ Impact Analyses ì¼ê´€ì„± ì²´í¬
        if impact_analyses:
            heatmap_block = None
            for block in strategy_section.get("blocks", []):
                if block.get("type") == "heatmap_table":
                    heatmap_block = block
                    break

            if heatmap_block:
                # Heatmap í—¤ë”ì˜ ë¦¬ìŠ¤í¬ ê°œìˆ˜ vs Impact Analyses ê°œìˆ˜
                headers = heatmap_block.get("data", {}).get("headers", [])
                # ì²« ë²ˆì§¸ëŠ” "ì‚¬ì—…ì¥", ë§ˆì§€ë§‰ì€ "Total AAL"ì´ë¯€ë¡œ ì œì™¸
                risk_count_in_heatmap = len(headers) - 2
                impact_count = len(impact_analyses)

                if risk_count_in_heatmap != impact_count:
                    issues.append({
                        "severity": "warning",
                        "type": "consistency",
                        "field": "heatmap_risks",
                        "message": f"Heatmap ë¦¬ìŠ¤í¬ ê°œìˆ˜({risk_count_in_heatmap})ì™€ Impact Analysis ê°œìˆ˜({impact_count})ê°€ ë¶ˆì¼ì¹˜"
                    })

        # 2. Priority Actions Tableê³¼ Impact Analyses ì¼ê´€ì„± ì²´í¬
        priority_table = strategy_section.get("priority_actions_table")
        if priority_table and impact_analyses:
            rows = priority_table.get("data", {}).get("rows", [])
            if len(rows) != len(impact_analyses):
                issues.append({
                    "severity": "warning",
                    "type": "consistency",
                    "field": "priority_table",
                    "message": f"Priority Table í–‰ ê°œìˆ˜({len(rows)})ì™€ Impact Analysis ê°œìˆ˜({len(impact_analyses)})ê°€ ë¶ˆì¼ì¹˜"
                })

        # 3. AAL ê°’ ë²”ìœ„ ì²´í¬
        # ì°¸ê³ : total_aalì€ ë©€í‹° ì‚¬ì´íŠ¸ í•©ê³„ì´ë¯€ë¡œ 100%ë¥¼ ì´ˆê³¼í•  ìˆ˜ ìˆìŒ (ì •ìƒ)
        # ê°œë³„ ì‚¬ì´íŠ¸ AALë§Œ 0-100% ë²”ìœ„ ê²€ì¦
        if impact_analyses:
            for i, impact in enumerate(impact_analyses, 1):
                # ê°œë³„ ì‚¬ì´íŠ¸ë³„ AAL ê²€ì¦ (site_aal_valuesê°€ ìˆëŠ” ê²½ìš°)
                site_aal_values = impact.get("site_aal_values", {})
                for site_name, aal in site_aal_values.items():
                    if aal < 0 or aal > 100:
                        issues.append({
                            "severity": "critical",
                            "type": "data_validity",
                            "field": f"impact_aal_p{i}_{site_name}",
                            "message": f"P{i} {site_name} AAL ê°’ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨: {aal}% (0-100% ë²”ìœ„)"
                        })

                # total_aalì´ ìŒìˆ˜ì¸ ê²½ìš°ë§Œ ì—ëŸ¬ (í•©ê³„ > 100%ëŠ” ë©€í‹°ì‚¬ì´íŠ¸ì—ì„œ ì •ìƒ)
                total_aal = impact.get("total_aal", 0.0)
                if total_aal < 0:
                    issues.append({
                        "severity": "critical",
                        "type": "data_validity",
                        "field": f"impact_aal_p{i}",
                        "message": f"P{i} AAL ê°’ì´ ìŒìˆ˜: {total_aal}%"
                    })

        return issues

    def _check_tcfd_principles(self, strategy_section: Dict) -> Dict[str, float]:
        """
        TCFD 7ëŒ€ ì›ì¹™ ê²€ì¦

        Args:
            strategy_section: Node 3 ì¶œë ¥

        Returns:
            Dict[str, float]: ì›ì¹™ë³„ ì ìˆ˜ (0-100)
        """
        scores = {}

        # 1. Relevant (ê´€ë ¨ì„±): Executive Summary ì¡´ì¬ ì—¬ë¶€
        has_exec_summary = any(
            b.get("subheading") == "Executive Summary"
            for b in strategy_section.get("blocks", [])
        )
        scores["Relevant"] = 100.0 if has_exec_summary else 50.0

        # 2. Specific (êµ¬ì²´ì„±): ì •ëŸ‰ì  ë°ì´í„° í¬í•¨ ì—¬ë¶€ (HeatmapTable, Priority Table)
        has_heatmap = any(
            b.get("type") == "heatmap_table"
            for b in strategy_section.get("blocks", [])
        )
        has_priority_table = strategy_section.get("priority_actions_table") is not None
        scores["Specific"] = 100.0 if (has_heatmap and has_priority_table) else 70.0

        # 3. Clear (ëª…í™•ì„±): ë¸”ë¡ êµ¬ì¡°í™” ì—¬ë¶€
        blocks = strategy_section.get("blocks", [])
        has_structure = len(blocks) >= 5 and all(
            "type" in b for b in blocks
        )
        scores["Clear"] = 100.0 if has_structure else 70.0

        # 4. Consistent (ì¼ê´€ì„±): ë°ì´í„° ê²€ì¦ì€ _check_data_consistencyì—ì„œ ìˆ˜í–‰
        scores["Consistent"] = 90.0  # ê¸°ë³¸ ì ìˆ˜ (ë°ì´í„° ì¼ê´€ì„± ì´ìŠˆê°€ ìˆìœ¼ë©´ ê°ì )

        # 5. Comparable (ë¹„êµê°€ëŠ¥ì„±): ì‹œë‚˜ë¦¬ì˜¤/ë¦¬ìŠ¤í¬ ë¹„êµ ê°€ëŠ¥ ì—¬ë¶€
        scores["Comparable"] = 85.0  # ê¸°ë³¸ ì ìˆ˜

        # 6. Reliable (ì‹ ë¢°ì„±): ë°ì´í„° ì¶œì²˜ ëª…í™•ì„±
        scores["Reliable"] = 90.0  # ê¸°ë³¸ ì ìˆ˜

        # 7. Timely (ì ì‹œì„±): ìµœì‹  ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        scores["Timely"] = 95.0  # ê¸°ë³¸ ì ìˆ˜ (2025ë…„ ê¸°ì¤€)

        return scores

    def _calculate_quality_score(
        self,
        issues: List[Dict],
        principle_scores: Dict[str, float]
    ) -> float:
        """
        í’ˆì§ˆ ì ìˆ˜ ì‚°ì¶œ (0-100ì )

        Args:
            issues: ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
            principle_scores: TCFD ì›ì¹™ë³„ ì ìˆ˜

        Returns:
            float: í’ˆì§ˆ ì ìˆ˜
        """
        # 1. ê¸°ë³¸ ì ìˆ˜ (TCFD ì›ì¹™ í‰ê· )
        base_score = sum(principle_scores.values()) / len(principle_scores)

        # 2. ì´ìŠˆ ê°ì 
        deduction = 0.0
        for issue in issues:
            if issue["severity"] == "critical":
                deduction += 20.0  # Critical ì´ìŠˆë‹¹ -20ì 
            elif issue["severity"] == "warning":
                deduction += 5.0   # Warning ì´ìŠˆë‹¹ -5ì 

        # 3. ìµœì¢… ì ìˆ˜ (ìµœì†Œ 0ì , ìµœëŒ€ 100ì )
        final_score = max(0.0, min(100.0, base_score - deduction))

        return final_score

    def _generate_feedback(self, issues: List[Dict], is_valid: bool) -> str:
        """
        í”¼ë“œë°± ë©”ì‹œì§€ ìƒì„±

        Args:
            issues: ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
            is_valid: ê²€ì¦ í†µê³¼ ì—¬ë¶€

        Returns:
            str: í”¼ë“œë°± ë©”ì‹œì§€
        """
        if is_valid and len(issues) == 0:
            return "âœ… ëª¨ë“  ê²€ì¦ í•­ëª©ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤. TCFD ë³´ê³ ì„œ í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤."

        feedback_parts = []

        if not is_valid:
            critical_issues = [i for i in issues if i["severity"] == "critical"]
            feedback_parts.append(f"âš ï¸  {len(critical_issues)}ê°œì˜ Critical ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
            for issue in critical_issues[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                feedback_parts.append(f"  - {issue['message']}")

        warning_issues = [i for i in issues if i["severity"] == "warning"]
        if warning_issues:
            feedback_parts.append(f"\nğŸ“‹ {len(warning_issues)}ê°œì˜ Warningì´ ìˆìŠµë‹ˆë‹¤:")
            for issue in warning_issues[:3]:  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                feedback_parts.append(f"  - {issue['message']}")

        if not feedback_parts:
            return "ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."

        return "\n".join(feedback_parts)
