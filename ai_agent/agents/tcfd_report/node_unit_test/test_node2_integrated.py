"""
Node 2 í†µí•© í…ŒìŠ¤íŠ¸ (2-A â†’ 2-B â†’ 2-C)

ì‹¤í–‰ ë°©ë²•:
    cd c:/Users/SKAX/Documents/POLARIS/polaris_backend_fastapi-develop
    python -m ai_agent.agents.tcfd_report.test_node2_integrated

í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ì‹¤ì œ LLM ì‚¬ìš© ì‹œ):
    set OPENAI_API_KEY=your_key_here
    set USE_REAL_LLM=true
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime


def create_sample_sites_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì‚¬ì—…ì¥ ë°ì´í„° ìƒì„± (8ê°œ ì‚¬ì—…ì¥)"""
    return [
        {
            "site_id": "site_001",
            "site_name": "ì„œìš¸ ë³¸ì‚¬",
            "risk_results": [
                {
                    "risk_type": "river_flood",
                    "final_aal": 7.2,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 7.2, "2030": 7.0, "2040": 6.5, "2050": 6.0, "2100": 5.5},
                        "ssp2_4.5": {"2025": 7.2, "2030": 7.5, "2040": 8.2, "2050": 9.0, "2100": 10.1},
                        "ssp3_7.0": {"2025": 7.2, "2030": 8.0, "2040": 9.5, "2050": 11.0, "2100": 12.5},
                        "ssp5_8.5": {"2025": 7.2, "2030": 8.5, "2040": 10.5, "2050": 13.0, "2100": 15.2}
                    }
                },
                {
                    "risk_type": "urban_flood",
                    "final_aal": 5.1,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 5.1, "2030": 5.0, "2040": 4.8, "2050": 4.5, "2100": 4.2},
                        "ssp2_4.5": {"2025": 5.1, "2030": 5.3, "2040": 5.8, "2050": 6.2, "2100": 6.8},
                        "ssp3_7.0": {"2025": 5.1, "2030": 5.8, "2040": 6.8, "2050": 7.5, "2100": 8.5},
                        "ssp5_8.5": {"2025": 5.1, "2030": 6.2, "2040": 7.8, "2050": 9.2, "2100": 11.0}
                    }
                }
            ]
        },
        {
            "site_id": "site_002",
            "site_name": "íŒêµ ë°ì´í„°ì„¼í„°",
            "risk_results": [
                {
                    "risk_type": "river_flood",
                    "final_aal": 11.0,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 11.0, "2030": 10.5, "2040": 10.0, "2050": 9.5, "2100": 9.0},
                        "ssp2_4.5": {"2025": 11.0, "2030": 11.5, "2040": 12.5, "2050": 13.5, "2100": 14.8},
                        "ssp3_7.0": {"2025": 11.0, "2030": 12.0, "2040": 14.0, "2050": 16.0, "2100": 18.0},
                        "ssp5_8.5": {"2025": 11.0, "2030": 13.0, "2040": 16.0, "2050": 19.0, "2100": 22.5}
                    }
                },
                {
                    "risk_type": "extreme_heat",
                    "final_aal": 5.5,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 5.5, "2030": 5.3, "2040": 5.0, "2050": 4.8, "2100": 4.5},
                        "ssp2_4.5": {"2025": 5.5, "2030": 6.0, "2040": 7.0, "2050": 8.0, "2100": 9.2},
                        "ssp3_7.0": {"2025": 5.5, "2030": 6.5, "2040": 8.0, "2050": 10.0, "2100": 12.0},
                        "ssp5_8.5": {"2025": 5.5, "2030": 7.0, "2040": 9.5, "2050": 12.0, "2100": 15.0}
                    }
                }
            ]
        },
        {
            "site_id": "site_003",
            "site_name": "ë¶€ì‚° ì‚¬ì—…ì¥",
            "risk_results": [
                {
                    "risk_type": "typhoon",
                    "final_aal": 9.3,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 9.3, "2030": 9.0, "2040": 8.5, "2050": 8.0, "2100": 7.5},
                        "ssp2_4.5": {"2025": 9.3, "2030": 9.8, "2040": 10.8, "2050": 11.5, "2100": 12.5},
                        "ssp3_7.0": {"2025": 9.3, "2030": 10.5, "2040": 12.5, "2050": 14.0, "2100": 15.8},
                        "ssp5_8.5": {"2025": 9.3, "2030": 11.5, "2040": 14.5, "2050": 17.0, "2100": 20.0}
                    }
                },
                {
                    "risk_type": "sea_level_rise",
                    "final_aal": 6.2,
                    "scenarios": {
                        "ssp1_2.6": {"2025": 6.2, "2030": 6.0, "2040": 5.8, "2050": 5.5, "2100": 5.2},
                        "ssp2_4.5": {"2025": 6.2, "2030": 6.5, "2040": 7.2, "2050": 8.0, "2100": 9.0},
                        "ssp3_7.0": {"2025": 6.2, "2030": 7.0, "2040": 8.5, "2050": 10.0, "2100": 12.0},
                        "ssp5_8.5": {"2025": 6.2, "2030": 7.8, "2040": 10.2, "2050": 13.0, "2100": 16.5}
                    }
                }
            ]
        }
    ]


def create_sample_report_template():
    """í…ŒìŠ¤íŠ¸ìš© Node 1 í…œí”Œë¦¿ ìƒì„±"""
    return {
        "tone": {
            "formality": "formal",
            "audience": "institutional investors and stakeholders",
            "voice": "data-driven, professional, transparent"
        },
        "scenario_templates": {
            "SSP1-2.6": {"name": "ì§€ì†ê°€ëŠ¥ ë°œì „", "temp_rise": "1.5Â°C", "style": "ë‚™ê´€ì "},
            "SSP2-4.5": {"name": "ì¤‘ê°„ ê²½ë¡œ", "temp_rise": "2.0-2.5Â°C", "style": "ì¤‘ë¦½ì "},
            "SSP5-8.5": {"name": "í™”ì„ì—°ë£Œ ì§‘ì•½", "temp_rise": "4.0Â°C+", "style": "ê²½ê³ ì "}
        },
        "hazard_template_blocks": {
            "river_flood": {
                "kr_name": "í•˜ì²œ ë²”ëŒ",
                "description_pattern": "[ë¦¬ìŠ¤í¬ëª…] ë¦¬ìŠ¤í¬ëŠ” [ì‚¬ì—…ì¥]ì— [ì˜í–¥]ì„ ë¯¸ì¹©ë‹ˆë‹¤."
            },
            "typhoon": {
                "kr_name": "íƒœí’",
                "description_pattern": "ê°•í’ ë° í­ìš°ë¡œ ì¸í•œ [ìì‚°] í”¼í•´"
            }
        },
        "formatting_rules": {
            "headings": "ìˆ«ì. ì œëª©",
            "emphasis": "**êµµì€ ê¸€ì”¨**"
        },
        "reusable_paragraphs": [
            "ìš°ë¦¬ëŠ” TCFD ê¶Œê³ ì•ˆì— ë”°ë¼ ê¸°í›„ë³€í™” ë¦¬ìŠ¤í¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.",
            "ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„ì„ í†µí•´ ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ì˜ ì¬ë¬´ì  ì˜í–¥ì„ ì •ëŸ‰í™”í–ˆìŠµë‹ˆë‹¤.",
            "ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ëŒ€ì‘ ì „ëµì„ ìˆ˜ë¦½í•˜ì—¬ ê¸°í›„ íšŒë³µë ¥ì„ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        ]
    }


class MockLLM:
    """Mock LLM (í…ŒìŠ¤íŠ¸ìš©)"""
    def __init__(self):
        self.call_count = 0

    async def ainvoke(self, prompt):
        self.call_count += 1
        print(f"\n{'='*60}")
        print(f"ğŸ¤– Mock LLM í˜¸ì¶œ #{self.call_count}")
        print(f"{'='*60}")
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt):,} ê¸€ì")

        # í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ë¶„ê¸°
        if "scenario" in prompt.lower() or "ì‹œë‚˜ë¦¬ì˜¤" in prompt:
            print("âœ… ì‘ë‹µ íƒ€ì…: ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")
            return self._mock_scenario_response()
        elif "impact" in prompt.lower() or "ì˜í–¥" in prompt:
            print("âœ… ì‘ë‹µ íƒ€ì…: ì˜í–¥ ë¶„ì„")
            return self._mock_impact_response()
        elif "mitigation" in prompt.lower() or "ëŒ€ì‘" in prompt or "ì „ëµ" in prompt:
            print("âœ… ì‘ë‹µ íƒ€ì…: ëŒ€ì‘ ì „ëµ")
            return self._mock_mitigation_response()
        else:
            print("âš ï¸  ì‘ë‹µ íƒ€ì…: ì¼ë°˜")
            return "Mock response"

    def _mock_scenario_response(self):
        return """
## Executive Summary
í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ì˜ ê¸°í›„ ë¦¬ìŠ¤í¬ëŠ” 4ê°€ì§€ SSP ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ í¬ê²Œ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
SSP1-2.6ì—ì„œëŠ” AALì´ ê°ì†Œí•˜ì§€ë§Œ, SSP5-8.5ì—ì„œëŠ” í¬ê²Œ ì¦ê°€í•  ì „ë§ì…ë‹ˆë‹¤.

## Scenario-by-Scenario Analysis

### SSP1-2.6 (ì§€ì†ê°€ëŠ¥ ë°œì „)
AALì€ 2025ë…„ì—ì„œ 2100ë…„ê¹Œì§€ ì ì§„ì ìœ¼ë¡œ ê°ì†Œí•©ë‹ˆë‹¤.

### SSP5-8.5 (í™”ì„ì—°ë£Œ ì§‘ì•½)
AALì€ 2025ë…„ì—ì„œ 2100ë…„ê¹Œì§€ ê¸‰ê²©íˆ ì¦ê°€í•©ë‹ˆë‹¤.

## Strategic Recommendations
ë‹¨ê¸°ì ìœ¼ë¡œëŠ” ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ëŒ€ë¹„ ê¸°ë³¸ íšŒë³µë ¥ êµ¬ì¶•ì´ í•„ìš”í•©ë‹ˆë‹¤.
"""

    def _mock_impact_response(self):
        return json.dumps({
            "financial_impact": "ì¬ë¬´ì  ì˜í–¥ì€ ì—°ê°„ 30-50ì–µì›ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.",
            "operational_impact": "ì£¼ìš” ì‚¬ì—…ì¥ì˜ ìš´ì˜ ì¤‘ë‹¨ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.",
            "asset_impact": "ë¬¼ë¦¬ì  ìì‚° ì†ìƒ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.",
            "summary": "ì¦‰ê°ì ì¸ ëŒ€ì‘ì´ í•„ìš”í•œ ë¦¬ìŠ¤í¬ì…ë‹ˆë‹¤."
        }, ensure_ascii=False)

    def _mock_mitigation_response(self):
        return json.dumps({
            "short_term": [
                "ë¹„ìƒ ëŒ€ì‘ ë§¤ë‰´ì–¼ ìˆ˜ë¦½",
                "ì·¨ì•½ ì§€ì  ê¸´ê¸‰ ì ê²€",
                "ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•"
            ],
            "mid_term": [
                "ë¬¼ë¦¬ì  ë°©ì–´ ì‹œì„¤ ì„¤ì¹˜",
                "ì„¤ë¹„ ë³´ê°• ê³µì‚¬"
            ],
            "long_term": [
                "ì¥ê¸°ì  ë¦¬ìŠ¤í¬ ì €ê° ê³„íš",
                "ì‚¬ì—…ì¥ ì¬ë°°ì¹˜ ê²€í† "
            ],
            "priority": "ë†’ìŒ",
            "priority_justification": "Top ë¦¬ìŠ¤í¬ë¡œ ìš°ì„  ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            "estimated_cost": "ì´ 100ì–µì›",
            "expected_benefit": "AAL 3%p ê°ì†Œ ì˜ˆìƒ",
            "implementation_considerations": "ì˜ˆì‚° í™•ë³´ í•„ìš”"
        }, ensure_ascii=False)


class RealLLM:
    """ì‹¤ì œ OpenAI LLM"""
    def __init__(self):
        from openai import AsyncOpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”")
        self.client = AsyncOpenAI(api_key=api_key)

    async def ainvoke(self, prompt):
        print(f"\nğŸš€ OpenAI API í˜¸ì¶œ ì¤‘...")
        response = await self.client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an ELITE ESG/TCFD analyst."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        result = response.choices[0].message.content
        print(f"âœ… API ì‘ë‹µ ì™„ë£Œ ({len(result)} ê¸€ì)")
        return result


async def main():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸ§ª Node 2 í†µí•© í…ŒìŠ¤íŠ¸ (2-A â†’ 2-B â†’ 2-C)")
    print("="*80)

    # ì ˆëŒ€ import
    project_root = Path(__file__).parent.parent.parent.parent
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

    from ai_agent.agents.tcfd_report.node_2a_scenario_analysis_v2 import ScenarioAnalysisNode
    from ai_agent.agents.tcfd_report.node_2b_impact_analysis_v2 import ImpactAnalysisNode
    from ai_agent.agents.tcfd_report.node_2c_mitigation_strategies_v2 import MitigationStrategiesNode

    # LLM ì„¤ì •
    use_real = os.getenv("USE_REAL_LLM", "false").lower() == "true"

    if use_real:
        print("\nğŸš€ ì‹¤ì œ OpenAI API ì‚¬ìš©")
        try:
            llm = RealLLM()
        except Exception as e:
            print(f"âŒ OpenAI ì„¤ì • ì‹¤íŒ¨: {e}")
            print("Mock LLMìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            llm = MockLLM()
    else:
        print("\nğŸ¤– Mock LLM ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)")
        llm = MockLLM()

    # ë…¸ë“œ ì´ˆê¸°í™”
    node_2a = ScenarioAnalysisNode(llm_client=llm)
    node_2b = ImpactAnalysisNode(llm_client=llm)
    node_2c = MitigationStrategiesNode(llm_client=llm)

    # ìƒ˜í”Œ ë°ì´í„°
    sites_data = create_sample_sites_data()
    report_template = create_sample_report_template()

    print("\nğŸ“„ ì…ë ¥ ë°ì´í„°:")
    print(f"  - ì‚¬ì—…ì¥ ê°œìˆ˜: {len(sites_data)}")
    print(f"  - í…œí”Œë¦¿ í•„ë“œ: {len(report_template)}")

    # =================================================================
    # STEP 1: Node 2-A (Scenario Analysis)
    # =================================================================
    print("\n" + "="*80)
    print("STEP 1: Node 2-A (Scenario Analysis) ì‹¤í–‰")
    print("="*80)

    result_2a = await node_2a.execute(
        sites_data=sites_data,
        report_template=report_template,
        agent_guideline=None
    )

    scenarios = result_2a["scenarios"]
    scenario_table = result_2a["scenario_table"]

    print(f"\nâœ… Node 2-A ì™„ë£Œ!")
    print(f"  - ì‹œë‚˜ë¦¬ì˜¤ ê°œìˆ˜: {len(scenarios)}")
    print(f"  - TableBlock ìƒì„±: {scenario_table.get('type')}")

    # ì‹œë‚˜ë¦¬ì˜¤ ìš”ì•½
    print(f"\n  ì‹œë‚˜ë¦¬ì˜¤ AAL ìš”ì•½:")
    for key, data in scenarios.items():
        aal_start = data.get("aal_values", [0])[0]
        aal_end = data.get("aal_values", [0])[-1]
        print(f"    {key.upper()}: {aal_start}% â†’ {aal_end}%")

    # =================================================================
    # STEP 2: Node 2-B (Impact Analysis)
    # =================================================================
    print("\n" + "="*80)
    print("STEP 2: Node 2-B (Impact Analysis) ì‹¤í–‰")
    print("="*80)

    result_2b = await node_2b.execute(
        sites_data=sites_data,
        scenario_analysis=result_2a,
        report_template=report_template,
        sites_metadata=None
    )

    top_5_risks = result_2b["top_5_risks"]
    impact_analyses = result_2b["impact_analyses"]
    impact_blocks = result_2b["impact_blocks"]

    print(f"\nâœ… Node 2-B ì™„ë£Œ!")
    print(f"  - Top 5 ë¦¬ìŠ¤í¬:")
    for risk in top_5_risks:
        print(f"    P{risk['rank']}. {risk['risk_type']}: AAL {risk['total_aal']}%")
    print(f"  - TextBlock ê°œìˆ˜: {len(impact_blocks)}")

    # =================================================================
    # STEP 3: Node 2-C (Mitigation Strategies)
    # =================================================================
    print("\n" + "="*80)
    print("STEP 3: Node 2-C (Mitigation Strategies) ì‹¤í–‰")
    print("="*80)

    result_2c = await node_2c.execute(
        impact_analyses=impact_analyses,
        report_template=report_template,
        company_context=None
    )

    mitigation_strategies = result_2c["mitigation_strategies"]
    mitigation_blocks = result_2c["mitigation_blocks"]
    implementation_roadmap = result_2c["implementation_roadmap"]

    print(f"\nâœ… Node 2-C ì™„ë£Œ!")
    print(f"  - ëŒ€ì‘ ì „ëµ ê°œìˆ˜: {len(mitigation_strategies)}")
    print(f"  - TextBlock ê°œìˆ˜: {len(mitigation_blocks)}")

    # ìš°ì„ ìˆœìœ„ ìš”ì•½
    priority_summary = {"ë§¤ìš° ë†’ìŒ": 0, "ë†’ìŒ": 0, "ì¤‘ê°„": 0}
    for strategy in mitigation_strategies:
        priority = strategy.get("priority", "ì¤‘ê°„")
        if priority in priority_summary:
            priority_summary[priority] += 1

    print(f"\n  ìš°ì„ ìˆœìœ„ ë¶„í¬:")
    for priority, count in priority_summary.items():
        print(f"    {priority}: {count}ê°œ")

    # =================================================================
    # í†µí•© ê²°ê³¼ ì •ë¦¬
    # =================================================================
    print("\n" + "="*80)
    print("ğŸ“Š í†µí•© ê²°ê³¼ ìš”ì•½")
    print("="*80)

    integrated_result = {
        "node_2a": {
            "scenarios": scenarios,
            "scenario_table": scenario_table,
            "scenario_text_block": result_2a["scenario_text_block"],
            "comparison_analysis": result_2a["comparison_analysis"]
        },
        "node_2b": {
            "top_5_risks": top_5_risks,
            "impact_analyses": impact_analyses,
            "impact_blocks": impact_blocks
        },
        "node_2c": {
            "mitigation_strategies": mitigation_strategies,
            "mitigation_blocks": mitigation_blocks,
            "implementation_roadmap": implementation_roadmap
        }
    }

    # ì „ì²´ í†µê³„
    print(f"\nì „ì²´ ìƒì„±ëœ JSON ë¸”ë¡:")
    print(f"  - TableBlock: 1ê°œ (Node 2-A)")
    print(f"  - TextBlock: {len(impact_blocks) + len(mitigation_blocks) + 1}ê°œ")
    print(f"    * Node 2-A: 1ê°œ (ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„)")
    print(f"    * Node 2-B: {len(impact_blocks)}ê°œ (P1~P5 ì˜í–¥ ë¶„ì„)")
    print(f"    * Node 2-C: {len(mitigation_blocks)}ê°œ (P1~P5 ëŒ€ì‘ ì „ëµ)")

    print(f"\nì£¼ìš” ì‚°ì¶œë¬¼:")
    print(f"  - 4ê°€ì§€ SSP ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„")
    print(f"  - Top 5 ë¬¼ë¦¬ì  ë¦¬ìŠ¤í¬ ì‹ë³„")
    print(f"  - 5ê°œ ë¦¬ìŠ¤í¬ë³„ ì˜í–¥ ë¶„ì„ (ì¬ë¬´/ìš´ì˜/ìì‚°)")
    print(f"  - 5ê°œ ë¦¬ìŠ¤í¬ë³„ ëŒ€ì‘ ì „ëµ (ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°)")
    print(f"  - ì „ì²´ ì‹¤í–‰ ë¡œë“œë§µ")

    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).parent / "test_output"
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"node2_integrated_{timestamp}.json"

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(integrated_result, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ í†µí•© ê²°ê³¼ ì €ì¥: {output_file}")

    # LLM í˜¸ì¶œ íšŸìˆ˜ (Mock LLMì¸ ê²½ìš°)
    if isinstance(llm, MockLLM):
        print(f"\nğŸ“Š Mock LLM í˜¸ì¶œ í†µê³„:")
        print(f"  - ì´ í˜¸ì¶œ íšŸìˆ˜: {llm.call_count}íšŒ")
        print(f"  - Node 2-A: 1íšŒ (ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„)")
        print(f"  - Node 2-B: {len(top_5_risks)}íšŒ (Top 5 ë³‘ë ¬ ë¶„ì„)")
        print(f"  - Node 2-C: {len(mitigation_strategies)}íšŒ (ëŒ€ì‘ ì „ëµ ë³‘ë ¬ ìƒì„±)")

    print("\n" + "="*80)
    print("âœ… Node 2 í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)

    if not use_real:
        print("\nğŸ’¡ ì‹¤ì œ OpenAI APIë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:")
        print("   1. set OPENAI_API_KEY=your_key")
        print("   2. set USE_REAL_LLM=true")
        print("   3. python -m ai_agent.agents.tcfd_report.test_node2_integrated")


if __name__ == "__main__":
    asyncio.run(main())
