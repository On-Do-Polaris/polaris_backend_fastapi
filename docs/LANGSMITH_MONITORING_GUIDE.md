# LangSmith ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-11-25
**ë²„ì „**: v1.0
**í”„ë¡œì íŠ¸**: SKAX Physical Risk Analysis System

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [LangSmithë€?](#langsmithë€)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
5. [íŠ¸ë ˆì´ì‹± êµ¬ì¡°](#íŠ¸ë ˆì´ì‹±-êµ¬ì¡°)
6. [ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•](#ëª¨ë‹ˆí„°ë§-ëŒ€ì‹œë³´ë“œ-ì‚¬ìš©ë²•)
7. [ì„±ëŠ¥ ë¶„ì„](#ì„±ëŠ¥-ë¶„ì„)
8. [ë””ë²„ê¹… ê°€ì´ë“œ](#ë””ë²„ê¹…-ê°€ì´ë“œ)
9. [ë¹„ìš© ìµœì í™”](#ë¹„ìš©-ìµœì í™”)
10. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

ë³¸ ë¬¸ì„œëŠ” SKAX Physical Risk Analysis Systemì—ì„œ LangSmithë¥¼ í™œìš©í•œ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ë¶„ì„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì‹œìŠ¤í…œ êµ¬ì„±

- **ì´ ì›Œí¬í”Œë¡œìš° ë…¸ë“œ**: 12ê°œ
- **ì´ Agent ìˆ˜**: 25ê°œ
  - Physical Risk Score Sub Agents: 9ê°œ
  - AAL Analysis Sub Agents: 9ê°œ
  - Report Generation Agents: 7ê°œ
- **LLM ì‚¬ìš©**: GPT-4 (OpenAI)
- **íŠ¸ë ˆì´ì‹± ë²”ìœ„**: ì „ì²´ ì›Œí¬í”Œë¡œìš° + ëª¨ë“  LLM í˜¸ì¶œ

---

## LangSmithë€?

LangSmithëŠ” LangChainì´ ì œê³µí•˜ëŠ” LLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê´€ì°°ì„±(Observability) í”Œë«í¼ì…ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥

1. **íŠ¸ë ˆì´ì‹± (Tracing)**
   - ëª¨ë“  LLM í˜¸ì¶œ ë° Agent ì‹¤í–‰ì„ ì¶”ì 
   - ì‹¤í–‰ ì‹œê°„, ì…ë ¥/ì¶œë ¥, ì—ëŸ¬ ë¡œê¹…

2. **ëª¨ë‹ˆí„°ë§ (Monitoring)**
   - ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­
   - ë¹„ìš© ì¶”ì  (í† í° ì‚¬ìš©ëŸ‰)
   - ì„±ê³µë¥ /ì‹¤íŒ¨ìœ¨ í†µê³„

3. **ë””ë²„ê¹… (Debugging)**
   - í”„ë¡¬í”„íŠ¸ í™•ì¸ ë° ê°œì„ 
   - ì²´ì¸/ì›Œí¬í”Œë¡œìš° ì‹œê°í™”
   - ì—ëŸ¬ ê·¼ë³¸ ì›ì¸ ë¶„ì„

4. **í‰ê°€ (Evaluation)**
   - LLM ì‘ë‹µ í’ˆì§ˆ í‰ê°€
   - A/B í…ŒìŠ¤íŠ¸ ì§€ì›
   - íšŒê·€ í…ŒìŠ¤íŠ¸

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### LangSmith í†µí•© êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangSmith Cloud                          â”‚
â”‚  https://smith.langchain.com                                â”‚
â”‚  - í”„ë¡œì íŠ¸: skax-physical-risk-dev                         â”‚
â”‚  - API Key: lsv2_pt_a8f35bdf8a6a49fbbb162eb289e0af7c_...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚ HTTPS (Tracing Data)
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SKAX Physical Risk Analyzer                   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Main Orchestrator (@traceable)                     â”‚   â”‚
â”‚  â”‚  - analyze()                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LangGraph Workflow (12 Nodes)                      â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  Node 1: data_collection (@traceable)               â”‚   â”‚
â”‚  â”‚  Node 2: vulnerability_analysis (@traceable)        â”‚   â”‚
â”‚  â”‚  Node 3: aal_analysis (@traceable)                  â”‚   â”‚
â”‚  â”‚  Node 3a: physical_risk_score (@traceable)          â”‚   â”‚
â”‚  â”‚  Node 4: risk_integration (@traceable)              â”‚   â”‚
â”‚  â”‚  Node 5: report_template (@traceable)               â”‚   â”‚
â”‚  â”‚  Node 6: impact_analysis (@traceable)               â”‚   â”‚
â”‚  â”‚  Node 7: strategy_generation (@traceable)           â”‚   â”‚
â”‚  â”‚  Node 8: report_generation (@traceable)             â”‚   â”‚
â”‚  â”‚  Node 9: validation (@traceable)                    â”‚   â”‚
â”‚  â”‚  Node 9a: refiner (@traceable)                      â”‚   â”‚
â”‚  â”‚  Node 10: finalization (@traceable)                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LLM Client (@traceable)                            â”‚   â”‚
â”‚  â”‚  - LangChain ChatOpenAI                             â”‚   â”‚
â”‚  â”‚  - invoke() / ainvoke()                             â”‚   â”‚
â”‚  â”‚  - generate_response_strategy()                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                         â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Report Generation Agents                           â”‚   â”‚
â”‚  â”‚  - ReportAnalysisAgent (@traceable)                 â”‚   â”‚
â”‚  â”‚  - ImpactAnalysisAgent                              â”‚   â”‚
â”‚  â”‚  - StrategyGenerationAgent                          â”‚   â”‚
â”‚  â”‚  - ReportComposerAgent                              â”‚   â”‚
â”‚  â”‚  - ValidationAgent                                  â”‚   â”‚
â”‚  â”‚  - RefinerAgent                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## í™˜ê²½ ì„¤ì •

### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.env)

```bash
# ===== LangSmith íŠ¸ë ˆì´ì‹± ì„¤ì • =====
LANGSMITH_ENABLED=true
LANGSMITH_API_KEY=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
LANGSMITH_PROJECT=skax-physical-risk-dev
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
LANGSMITH_SAMPLING_RATE=1.0

# ===== OpenAI API ì„¤ì • =====
OPENAI_API_KEY=your_openai_api_key_here
```

### 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install langsmith
pip install langchain-openai
pip install langchain-core
```

### 3. ì„¤ì • í™•ì¸

```python
from ai_agent.config.settings import Config

config = Config()
print(f"LangSmith Enabled: {config.LANGSMITH_CONFIG['enabled']}")
print(f"Project: {config.LANGSMITH_CONFIG['project_name']}")
print(f"Sampling Rate: {config.LANGSMITH_CONFIG['sampling_rate']}")
```

### 4. í™˜ê²½ë³„ ì„¤ì •

#### Development í™˜ê²½
```python
from ai_agent.config.settings import DevelopmentConfig

config = DevelopmentConfig()
# LangSmith Project: skax-physical-risk-dev
# Sampling Rate: 100% (ì „ì²´ ì¶”ì )
```

#### Production í™˜ê²½
```python
from ai_agent.config.settings import ProductionConfig

config = ProductionConfig()
# LangSmith Project: skax-physical-risk-prod
# Tags: ['production', 'monitoring']
```

#### Test í™˜ê²½
```python
from ai_agent.config.settings import TestConfig

config = TestConfig()
# LangSmith Disabled (CI ì„±ëŠ¥ ìµœì í™”)
```

---

## íŠ¸ë ˆì´ì‹± êµ¬ì¡°

### íŠ¸ë ˆì´ìŠ¤ ê³„ì¸µ êµ¬ì¡°

```
skax_physical_risk_analyze (Root Trace)
â”‚
â”œâ”€ data_collection_node
â”‚  â””â”€ DataCollectionAgent.collect()
â”‚
â”œâ”€ vulnerability_analysis_node
â”‚  â””â”€ VulnerabilityAnalysisAgent.analyze()
â”‚
â”œâ”€ aal_analysis_node (ë³‘ë ¬)
â”‚  â”œâ”€ ExtremeHeatAALAgent.analyze_aal()
â”‚  â”œâ”€ ExtremeColdAALAgent.analyze_aal()
â”‚  â”œâ”€ WildfireAALAgent.analyze_aal()
â”‚  â”œâ”€ DroughtAALAgent.analyze_aal()
â”‚  â”œâ”€ WaterStressAALAgent.analyze_aal()
â”‚  â”œâ”€ SeaLevelRiseAALAgent.analyze_aal()
â”‚  â”œâ”€ RiverFloodAALAgent.analyze_aal()
â”‚  â”œâ”€ UrbanFloodAALAgent.analyze_aal()
â”‚  â””â”€ TyphoonAALAgent.analyze_aal()
â”‚
â”œâ”€ physical_risk_score_node (ë³‘ë ¬)
â”‚  â”œâ”€ ExtremeHeatScoreAgent.calculate()
â”‚  â”œâ”€ ExtremeColdScoreAgent.calculate()
â”‚  â”œâ”€ WildfireScoreAgent.calculate()
â”‚  â”œâ”€ DroughtScoreAgent.calculate()
â”‚  â”œâ”€ WaterStressScoreAgent.calculate()
â”‚  â”œâ”€ SeaLevelRiseScoreAgent.calculate()
â”‚  â”œâ”€ RiverFloodScoreAgent.calculate()
â”‚  â”œâ”€ UrbanFloodScoreAgent.calculate()
â”‚  â””â”€ TyphoonScoreAgent.calculate()
â”‚
â”œâ”€ risk_integration_node
â”‚
â”œâ”€ report_template_node
â”‚  â””â”€ report_analysis_agent_run_sync
â”‚     â”œâ”€ RAGEngine.query()
â”‚     â””â”€ llm_invoke (LLM Call #1)
â”‚
â”œâ”€ impact_analysis_node
â”‚  â””â”€ ImpactAnalysisAgent.analyze_impact()
â”‚     â””â”€ llm_invoke (LLM Call #2)
â”‚
â”œâ”€ strategy_generation_node
â”‚  â””â”€ StrategyGenerationAgent.generate_strategy()
â”‚     â”œâ”€ RAGEngine.query()
â”‚     â””â”€ llm_invoke (LLM Call #3)
â”‚
â”œâ”€ report_generation_node
â”‚  â””â”€ ReportComposerAgent.compose_report()
â”‚     â””â”€ llm_invoke (LLM Call #4)
â”‚
â”œâ”€ validation_node
â”‚  â””â”€ ValidationAgent.validate_report()
â”‚
â”œâ”€ refiner_node (ì¡°ê±´ë¶€)
â”‚  â””â”€ RefinerAgent.refine_sync()
â”‚     â””â”€ llm_invoke (LLM Call #5)
â”‚
â””â”€ finalization_node
   â””â”€ FinalizerNode.run()
```

### íŠ¸ë ˆì´ìŠ¤ íƒœê·¸ ì²´ê³„

| íƒœê·¸ | ìš©ë„ | ì˜ˆì‹œ |
|------|------|------|
| `workflow` | ì›Œí¬í”Œë¡œìš° ë…¸ë“œ | `workflow`, `node` |
| `agent` | Agent ì‹¤í–‰ | `agent`, `report-analysis` |
| `llm` | LLM í˜¸ì¶œ | `llm`, `invoke`, `async` |
| `rag` | RAG ê²€ìƒ‰ | `rag`, `search` |
| `parallel` | ë³‘ë ¬ ì‹¤í–‰ | `parallel`, `aal`, `physical-risk` |

---

## ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‚¬ìš©ë²•

### 1. LangSmith ëŒ€ì‹œë³´ë“œ ì ‘ì†

1. https://smith.langchain.com ì ‘ì†
2. ë¡œê·¸ì¸ (API í‚¤ë¡œ ì¸ì¦)
3. í”„ë¡œì íŠ¸ ì„ íƒ: `skax-physical-risk-dev`

### 2. íŠ¸ë ˆì´ìŠ¤ ëª©ë¡ í™•ì¸

**ê²½ë¡œ**: Projects > skax-physical-risk-dev > Traces

#### ì£¼ìš” ì»¬ëŸ¼
- **Name**: íŠ¸ë ˆì´ìŠ¤ ì´ë¦„ (`skax_physical_risk_analyze`)
- **Status**: ì„±ê³µ/ì‹¤íŒ¨ (âœ… / âŒ)
- **Latency**: ì‹¤í–‰ ì‹œê°„ (ì´ˆ)
- **Tokens**: í† í° ì‚¬ìš©ëŸ‰
- **Cost**: ì˜ˆìƒ ë¹„ìš© (USD)
- **Start Time**: ì‹¤í–‰ ì‹œì‘ ì‹œê°„

#### í•„í„°ë§
```
# íƒœê·¸ë¡œ í•„í„°ë§
tags: workflow
tags: llm

# ìƒíƒœë¡œ í•„í„°ë§
status: error
status: success

# ì‹œê°„ ë²”ìœ„
Last 1 hour
Last 24 hours
Custom range
```

### 3. ê°œë³„ íŠ¸ë ˆì´ìŠ¤ ìƒì„¸ ë¶„ì„

**íŠ¸ë ˆì´ìŠ¤ í´ë¦­ ì‹œ í‘œì‹œ ì •ë³´**:

#### Overview íƒ­
- ì „ì²´ ì‹¤í–‰ ì‹œê°„
- ì´ í† í° ì‚¬ìš©ëŸ‰
- ì´ ë¹„ìš©
- ì„±ê³µ/ì‹¤íŒ¨ ìƒíƒœ

#### Timeline íƒ­
- ê° ë…¸ë“œë³„ ì‹¤í–‰ ìˆœì„œ ì‹œê°í™”
- Waterfall ì°¨íŠ¸ (ì‹¤í–‰ ì‹œê°„ ë¹„êµ)
- ë³‘ë ¬ ì‹¤í–‰ êµ¬ê°„ í‘œì‹œ

#### Inputs/Outputs íƒ­
```json
// Input ì˜ˆì‹œ
{
  "target_location": {
    "latitude": 37.5665,
    "longitude": 126.9780,
    "name": "Seoul, South Korea"
  },
  "building_info": {
    "building_age": 25,
    "has_seismic_design": true,
    "fire_access": true
  }
}

// Output ì˜ˆì‹œ
{
  "workflow_status": "completed",
  "physical_risk_scores": {...},
  "aal_analysis": {...},
  "generated_report": {...}
}
```

#### Metadata íƒ­
- Agent ì •ë³´
- ì‹¤í–‰ í™˜ê²½
- ì—ëŸ¬ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ (ì‹¤íŒ¨ ì‹œ)

### 4. LLM í˜¸ì¶œ ìƒì„¸ ë¶„ì„

**LLM Call í´ë¦­ ì‹œ í‘œì‹œ ì •ë³´**:

- **Prompt**: ì „ì†¡ëœ í”„ë¡¬í”„íŠ¸ ì „ì²´
- **Completion**: LLM ì‘ë‹µ
- **Model**: ì‚¬ìš©ëœ ëª¨ë¸ (gpt-4)
- **Tokens**:
  - Prompt Tokens: ì…ë ¥ í† í°
  - Completion Tokens: ì¶œë ¥ í† í°
  - Total Tokens: ì´í•©
- **Cost**: ì˜ˆìƒ ë¹„ìš©
- **Latency**: ì‘ë‹µ ì‹œê°„

---

## ì„±ëŠ¥ ë¶„ì„

### 1. ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„ ë¶„ì„

#### Metrics ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸

```
# í‰ê·  ì‹¤í–‰ ì‹œê°„
Average Latency by Tag

workflow, node, data-collection: 15.2s
workflow, node, aal, parallel: 45.8s
workflow, node, physical-risk, parallel: 42.3s
workflow, node, impact, llm: 8.5s
workflow, node, strategy, llm, rag: 12.3s
```

#### ë³‘ëª© êµ¬ê°„ ì‹ë³„

**ê¸°ì¤€**:
- ğŸŸ¢ ì •ìƒ: < 10ì´ˆ
- ğŸŸ¡ ì£¼ì˜: 10-30ì´ˆ
- ğŸ”´ ë³‘ëª©: > 30ì´ˆ

**ì¼ë°˜ì ì¸ ë³‘ëª©**:
1. AAL Analysis Node (9ê°œ Sub Agent ì‹¤í–‰)
2. Physical Risk Score Node (9ê°œ Sub Agent ì‹¤í–‰)
3. Strategy Generation Node (RAG + LLM)

### 2. LLM í† í° ì‚¬ìš©ëŸ‰ ë¶„ì„

#### í”„ë¡¬í”„íŠ¸ë³„ í† í° í†µê³„

| Agent | Avg Prompt Tokens | Avg Completion Tokens | Total Tokens |
|-------|-------------------|----------------------|--------------|
| ReportAnalysisAgent | 3,200 | 1,500 | 4,700 |
| ImpactAnalysisAgent | 2,800 | 1,200 | 4,000 |
| StrategyGenerationAgent | 3,500 | 1,800 | 5,300 |
| ReportComposerAgent | 4,000 | 2,000 | 6,000 |
| RefinerAgent | 3,000 | 1,500 | 4,500 |

#### ë¹„ìš© ì¶”ì • (GPT-4 ê¸°ì¤€)

```
Input: $0.03 / 1K tokens
Output: $0.06 / 1K tokens

1íšŒ ì‹¤í–‰ ì˜ˆìƒ ë¹„ìš©:
- Prompt: 16,500 tokens Ã— $0.03 / 1K = $0.495
- Completion: 8,000 tokens Ã— $0.06 / 1K = $0.480
- Total: $0.975
```

### 3. ì„±ê³µë¥ /ì‹¤íŒ¨ìœ¨ ëª¨ë‹ˆí„°ë§

#### Analytics ëŒ€ì‹œë³´ë“œ

```
# ìµœê·¼ 24ì‹œê°„
Total Runs: 120
Successful: 112 (93.3%)
Failed: 8 (6.7%)

# ì‹¤íŒ¨ ì›ì¸ ë¶„ë¥˜
- LLM Timeout: 4
- Validation Failed: 2
- Data Collection Error: 2
```

---

## ë””ë²„ê¹… ê°€ì´ë“œ

### 1. ì—ëŸ¬ ì¶”ì 

#### ì—ëŸ¬ ë°œìƒ ì‹œ í™•ì¸ ì ˆì°¨

1. **íŠ¸ë ˆì´ìŠ¤ ëª©ë¡ì—ì„œ ì‹¤íŒ¨í•œ ì‹¤í–‰ í•„í„°ë§**
   ```
   status: error
   ```

2. **ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤ í´ë¦­ â†’ Timeline í™•ì¸**
   - ì–´ëŠ ë…¸ë“œì—ì„œ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸
   - ë¹¨ê°„ìƒ‰ìœ¼ë¡œ í‘œì‹œëœ ë…¸ë“œ ì‹ë³„

3. **ì‹¤íŒ¨ ë…¸ë“œ í´ë¦­ â†’ Metadata íƒ­**
   ```python
   Error: JSONDecodeError: Expecting value: line 1 column 1 (char 0)

   Stack Trace:
     File "report_analysis_agent_1.py", line 128, in run_sync
       profile = self._sanitize_llm_response(llm_resp_raw)
     File "report_analysis_agent_1.py", line 294, in _sanitize_llm_response
       llm_resp = json.loads(llm_resp)
   ```

4. **Inputs/Outputs íƒ­ì—ì„œ í”„ë¡¬í”„íŠ¸ í™•ì¸**
   - ì…ë ¥ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦
   - í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í™•ì¸

### 2. í”„ë¡¬í”„íŠ¸ ìµœì í™”

#### Before (ë¹„íš¨ìœ¨ì )

```python
prompt = f"Analyze the report: {report_text}"
# Tokens: 15,000 (ë„ˆë¬´ ë§ì€ ì»¨í…ìŠ¤íŠ¸)
```

#### After (ìµœì í™”)

```python
# ìš”ì•½ë³¸ë§Œ ì „ë‹¬
summary = report_text[:2000]
prompt = f"Analyze the report summary: {summary}"
# Tokens: 3,000 (80% ê°ì†Œ)
```

#### í”„ë¡¬í”„íŠ¸ ê°œì„  ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ë¶ˆí•„ìš”í•œ ì»¨í…ìŠ¤íŠ¸ ì œê±°
- [ ] JSON ì¶œë ¥ í˜•ì‹ ëª…ì‹œ
- [ ] Few-shot ì˜ˆì‹œ ì¶”ê°€
- [ ] ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìµœì í™”

### 3. Retry ë¡œì§ ë¶„ì„

#### Validation Retry Loop ì¶”ì 

```
validation_node (Attempt 1) â†’ Failed
  â””â”€ Issues: text_quality, structure_incomplete

refiner_node (Loop 1) â†’ Completed
  â””â”€ Applied 3 fixes

validation_node (Attempt 2) â†’ Failed
  â””â”€ Issues: citation_missing

refiner_node (Loop 2) â†’ Completed
  â””â”€ Applied 1 fix

validation_node (Attempt 3) â†’ Passed âœ…
```

---

## ë¹„ìš© ìµœì í™”

### 1. ìƒ˜í”Œë§ ë¹„ìœ¨ ì¡°ì •

#### Development í™˜ê²½
```bash
# .env
LANGSMITH_SAMPLING_RATE=1.0  # 100% ì¶”ì  (ë””ë²„ê¹…)
```

#### Production í™˜ê²½
```bash
# .env
LANGSMITH_SAMPLING_RATE=0.1  # 10% ìƒ˜í”Œë§ (ë¹„ìš© ì ˆê°)
```

#### ë™ì  ìƒ˜í”Œë§

```python
# config/settings.py
import random

class ProductionConfig(Config):
    def __init__(self):
        super().__init__()

        # ì—ëŸ¬ ë°œìƒ ì‹œ 100% ì¶”ì , ì •ìƒ ì‹œ 10% ìƒ˜í”Œë§
        self.LANGSMITH_CONFIG['sampling_function'] = lambda: (
            1.0 if has_error else 0.1
        )
```

### 2. ëª¨ë¸ ì„ íƒ ìµœì í™”

#### íƒœìŠ¤í¬ë³„ ëª¨ë¸ ì „ëµ

| Agent | í˜„ì¬ ëª¨ë¸ | ê¶Œì¥ ëª¨ë¸ | ë¹„ìš© ì ˆê° |
|-------|----------|----------|----------|
| ReportAnalysisAgent | GPT-4 | GPT-4 | - |
| ImpactAnalysisAgent | GPT-4 | GPT-3.5-Turbo | 90% |
| StrategyGenerationAgent | GPT-4 | GPT-4 | - |
| ReportComposerAgent | GPT-4 | GPT-4 | - |
| ValidationAgent | GPT-4 | GPT-3.5-Turbo | 90% |
| RefinerAgent | GPT-4 | GPT-3.5-Turbo | 90% |

#### êµ¬í˜„ ì˜ˆì‹œ

```python
# llm_client.py
class LLMClient:
    def __init__(self, model: str = 'gpt-4', task_type: str = 'general'):
        # íƒœìŠ¤í¬ë³„ ëª¨ë¸ ì„ íƒ
        if task_type in ['validation', 'refine', 'impact']:
            model = 'gpt-3.5-turbo'

        self.llm = ChatOpenAI(model=model, ...)
```

### 3. ìºì‹± ì „ëµ

#### RAG ê²°ê³¼ ìºì‹±

```python
# utils/rag_engine.py
from functools import lru_cache

class RAGEngine:
    @lru_cache(maxsize=128)
    def query(self, query: str, top_k: int = 20):
        # ë™ì¼ ì¿¼ë¦¬ëŠ” ìºì‹œì—ì„œ ë°˜í™˜
        return self._search(query, top_k)
```

#### LLM ì‘ë‹µ ìºì‹±

```python
# LangChain ë‚´ì¥ ìºì‹±
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache

set_llm_cache(InMemoryCache())
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: íŠ¸ë ˆì´ìŠ¤ê°€ LangSmithì— í‘œì‹œë˜ì§€ ì•ŠìŒ

**ì¦ìƒ**:
- ì›Œí¬í”Œë¡œìš°ëŠ” ì •ìƒ ì‹¤í–‰ë˜ë‚˜ LangSmithì— íŠ¸ë ˆì´ìŠ¤ ì—†ìŒ

**ì›ì¸**:
1. í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •
2. API í‚¤ ì˜¤ë¥˜
3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ

**í•´ê²° ë°©ë²•**:

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $LANGCHAIN_TRACING_V2  # "true" ì¶œë ¥ í™•ì¸
echo $LANGCHAIN_API_KEY     # API í‚¤ í™•ì¸
echo $LANGCHAIN_PROJECT     # í”„ë¡œì íŠ¸ëª… í™•ì¸

# 2. Pythonì—ì„œ í™•ì¸
python -c "
import os
print('Tracing:', os.getenv('LANGCHAIN_TRACING_V2'))
print('Project:', os.getenv('LANGCHAIN_PROJECT'))
print('API Key:', os.getenv('LANGCHAIN_API_KEY')[:10] + '...')
"

# 3. ìˆ˜ë™ íŠ¸ë ˆì´ìŠ¤ í…ŒìŠ¤íŠ¸
python
>>> from langsmith import Client
>>> client = Client()
>>> client.list_projects()  # í”„ë¡œì íŠ¸ ëª©ë¡ í™•ì¸
```

### ë¬¸ì œ 2: LLM í˜¸ì¶œì´ ë„ˆë¬´ ëŠë¦¼

**ì¦ìƒ**:
- í‰ê·  ì‘ë‹µ ì‹œê°„ > 30ì´ˆ
- LangSmithì—ì„œ ê¸´ Latency í™•ì¸

**ì›ì¸**:
1. í”„ë¡¬í”„íŠ¸ í¬ê¸° ê³¼ë‹¤ (> 8K tokens)
2. ëª¨ë¸ ê³¼ë¶€í•˜
3. Rate Limit ë„ë‹¬

**í•´ê²° ë°©ë²•**:

```python
# 1. í”„ë¡¬í”„íŠ¸ í¬ê¸° í™•ì¸
from tiktoken import encoding_for_model

enc = encoding_for_model("gpt-4")
tokens = enc.encode(prompt)
print(f"Prompt tokens: {len(tokens)}")

# 2. í”„ë¡¬í”„íŠ¸ ì••ì¶•
def compress_prompt(text: str, max_tokens: int = 4000):
    enc = encoding_for_model("gpt-4")
    tokens = enc.encode(text)
    if len(tokens) > max_tokens:
        compressed = enc.decode(tokens[:max_tokens])
        return compressed + "\n\n[... ë‚´ìš© ì••ì¶•ë¨ ...]"
    return text

# 3. Timeout ì„¤ì •
llm = ChatOpenAI(
    model="gpt-4",
    timeout=30,  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    request_timeout=30
)
```

### ë¬¸ì œ 3: ë¹„ìš©ì´ ì˜ˆìƒë³´ë‹¤ ë†’ìŒ

**ì¦ìƒ**:
- ì›” ë¹„ìš© > $1,000
- LangSmithì—ì„œ ë†’ì€ í† í° ì‚¬ìš©ëŸ‰

**ë¶„ì„**:

```python
# LangSmith Analyticsì—ì„œ í™•ì¸
# Metrics > Cost by Tag

# ë¹„ìš© ìƒìœ„ Agent ì‹ë³„
Top Cost Contributors:
1. ReportComposerAgent: $350/month
2. StrategyGenerationAgent: $280/month
3. ReportAnalysisAgent: $220/month
```

**ìµœì í™”**:

```python
# 1. ë¶ˆí•„ìš”í•œ LLM í˜¸ì¶œ ì œê±°
# Before
for risk in risks:
    llm_analysis = llm.invoke(f"Analyze {risk}")  # 9ë²ˆ í˜¸ì¶œ

# After
batch_prompt = f"Analyze all risks: {risks}"
llm_analysis = llm.invoke(batch_prompt)  # 1ë²ˆ í˜¸ì¶œ

# 2. ìºì‹± í™œì„±í™”
from langchain.cache import RedisCache
set_llm_cache(RedisCache())

# 3. ìƒ˜í”Œë§ ë¹„ìœ¨ ë‚®ì¶”ê¸°
LANGSMITH_SAMPLING_RATE=0.1  # 10%ë§Œ ì¶”ì 
```

### ë¬¸ì œ 4: Refiner Loopê°€ ë¬´í•œ ë°˜ë³µ

**ì¦ìƒ**:
- Validation ê³„ì† ì‹¤íŒ¨
- Refiner Loop 3íšŒ ì´ˆê³¼

**ë””ë²„ê¹…**:

```python
# LangSmithì—ì„œ Refiner íŠ¸ë ˆì´ìŠ¤ í™•ì¸
refiner_node (Loop 1)
  Input: validation_result = {
    "issues_found": ["text_quality", "citation_missing"]
  }
  Output: applied_fixes = ["fixed_grammar", "added_citations"]

refiner_node (Loop 2)
  Input: validation_result = {
    "issues_found": ["text_quality"]  # ì—¬ì „íˆ ì‹¤íŒ¨
  }
  # Refinerê°€ ë™ì¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ì§€ ëª»í•¨
```

**í•´ê²°**:

```python
# agents/report_generation/refiner_agent_6.py

# Refiner í”„ë¡¬í”„íŠ¸ ê°œì„ 
def refine_sync(self, draft_markdown, validation_results):
    issues = validation_results.get("issues_found", [])

    # ì´ìŠˆë³„ êµ¬ì²´ì  ì§€ì‹œ
    fix_instructions = {
        "text_quality": "ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì • ë° ë¬¸ì¥ ë‹¤ë“¬ê¸°",
        "citation_missing": "ëˆ„ë½ëœ ì¸ìš© ì¶”ê°€ (ìµœì†Œ 3ê°œ)",
        "structure_incomplete": "ëˆ„ë½ëœ ì„¹ì…˜ ì¶”ê°€"
    }

    prompt = f"""
    ë‹¤ìŒ ì´ìŠˆë¥¼ ë°˜ë“œì‹œ í•´ê²°í•˜ì„¸ìš”:
    {[fix_instructions[issue] for issue in issues]}

    Draft: {draft_markdown}
    """
```

---

## ë¶€ë¡

### A. LangSmith API ì‚¬ìš© ì˜ˆì‹œ

#### í”„ë¡œê·¸ë˜ë° ë°©ì‹ íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ

```python
from langsmith import Client

client = Client()

# ìµœê·¼ 10ê°œ íŠ¸ë ˆì´ìŠ¤ ì¡°íšŒ
runs = client.list_runs(
    project_name="skax-physical-risk-dev",
    limit=10
)

for run in runs:
    print(f"Run ID: {run.id}")
    print(f"Name: {run.name}")
    print(f"Status: {run.status}")
    print(f"Latency: {run.total_time}s")
    print(f"Tokens: {run.total_tokens}")
    print("---")
```

#### ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡

```python
from langsmith import traceable

@traceable(
    name="custom_analysis",
    metadata={"version": "1.0", "env": "production"}
)
def analyze_custom(data):
    # ë¶„ì„ ë¡œì§
    result = process(data)

    # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì¶”ê°€
    return {
        "result": result,
        "metrics": {
            "accuracy": 0.95,
            "confidence": 0.88
        }
    }
```

### B. ì°¸ê³  ìë£Œ

- [LangSmith ê³µì‹ ë¬¸ì„œ](https://docs.smith.langchain.com/)
- [LangChain íŠ¸ë ˆì´ì‹± ê°€ì´ë“œ](https://python.langchain.com/docs/langsmith/tracing)
- [OpenAI ê°€ê²© ì •ì±…](https://openai.com/pricing)
- [SKAX ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¬¸ì„œ](./ARCHITECTURE.md)

### C. ì—°ë½ì²˜

**ê¸°ìˆ  ì§€ì›**:
- Email: support@skax.com
- Slack: #skax-physical-risk

**LangSmith ê´€ë ¨ ë¬¸ì˜**:
- LangChain Community: https://discord.gg/langchain

---

**ë¬¸ì„œ ë**
